{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c176a379",
   "metadata": {},
   "source": [
    "## ğŸ† ì²œí•˜ì œì¼ RAG ëŒ€íšŒ\n",
    "\n",
    "ì§€ê¸ˆê¹Œì§€ ìš°ë¦¬ëŠ” RAG ì„±ëŠ¥ì„ ìµœì í™”í•˜ê¸° ìœ„í•œ  \n",
    "ë‹¤ì–‘í•œ ê¸°ë²•ê³¼ ì „ëµë“¤ì„ ë‹¨ê³„ì ìœ¼ë¡œ í•™ìŠµí•´ ì™”ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ì œ ê·¸ë™ì•ˆ ë°°ìš´ ë‚´ìš©ì„ ì¢…í•©í•´,  \n",
    "**ê°€ì¥ ì •í™•í•˜ê³  íš¨ìœ¨ì ì¸ RAG ì±—ë´‡**ì„ ì§ì ‘ ë§Œë“¤ì–´ë³´ëŠ” ë¯¸ì…˜ì— ë„ì „í•©ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "ì´ë²ˆ ëŒ€íšŒì—ì„œ ì‚¬ìš©í•˜ëŠ” ë¬¸ì„œëŠ”  **ã€ì˜¤í”¼ìŠ¤ ì”í˜¹ ë™í™”: ì‹ ì… ì‚¬ì› ë¯¼ìˆ˜ã€ PDF**ì…ë‹ˆë‹¤.\n",
    "\n",
    "í•´ë‹¹ ë¬¸ì„œëŠ” ë„ë¦¬ ì•Œë ¤ì§„ ì‘í’ˆ(ì˜ˆ: *ì–´ë¦° ì™•ì*)ì˜ **ì„œì‚¬ êµ¬ì¡°ë¥¼ ì°¸ê³ í•˜ë˜**,  \n",
    "í‰ê°€ ëª©ì ì— ë§ê²Œ **ì¼ë¶€ ì„¤ì •ê³¼ í‘œí˜„ì´ ë³€í˜•ëœ ë¹„ê³µê°œ í…ìŠ¤íŠ¸**ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë”°ë¼ì„œ ì´ë²ˆ ë¯¸ì…˜ì˜ í•µì‹¬ì€ ìƒì‹ì´ë‚˜ ì‚¬ì „í•™ìŠµ ì§€ì‹ì— ì˜ì¡´í•´ ë‹µì„ ë§íˆëŠ” ê²ƒì´ ì•„ë‹ˆë¼,  \n",
    "**Retrieverê°€ ì‹¤ì œë¡œ ì°¾ì•„ì˜¨ ë¬¸ì„œ ê·¼ê±°ë¥¼ ì–¼ë§ˆë‚˜ ì˜ í™œìš©í•˜ëŠëƒ**ì— ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "ì°¸ê°€ìëŠ” ì´ë¯¸ ì œê³µëœ PDF ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, ì§ˆë¬¸ì— ëŒ€í•´ ë¬¸ì„œì—ì„œ ê´€ë ¨ ê·¼ê±°ë¥¼ ê²€ìƒ‰í•˜ê³   \n",
    "**ì •ë‹µë§Œ ê°„ê²°í•˜ê²Œ ì¶œë ¥í•˜ëŠ” ì±—ë´‡**ì„ êµ¬í˜„í•˜ê²Œ ë©ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "ğŸ… **1ë“± ìˆ˜ìƒìì—ê²ŒëŠ” ìƒê¸ˆ(50000) ë˜ëŠ” ë§›ìˆëŠ” ì‹ì‚¬ê°€ ì œê³µë©ë‹ˆë‹¤.**\n",
    "\n",
    "â€» ì ìˆ˜ê°€ ë™ì¼í•  ê²½ìš°  \n",
    "- **k ê°’ì´ ë” ì‘ì€ ì„¤ì •**,  \n",
    "- **ì²­í¬ ê¸¸ì´ê°€ ë” ì§§ì€ ì„¤ì •**\n",
    "- **ì½”ë“œì— ì£¼ì„ì„ ì¹œì ˆíˆ ì‘ì„±í•œ**  ì°¸ê°€ìë¥¼  \n",
    "ìš°ì„  ìˆœìœ„ë¡œ 1ë“±ìœ¼ë¡œ ì„ ì •í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1245edc",
   "metadata": {},
   "source": [
    "### ğŸ’¬ í‰ê°€ ì§ˆë¬¸(20ê°œ)\n",
    "ğŸ’¬ ì§ˆë¬¸: ì´ì•¼ê¸°ì˜ ì œëª©ì€ ë¬´ì—‡ì¸ê°€ìš”? | ğŸ“˜ ì •ë‹µ: ì˜¤í”¼ìŠ¤ ì”í˜¹ ë™í™”: ì‹ ì… ì‚¬ì› ë¯¼ìˆ˜  \n",
    "ğŸ’¬ ì§ˆë¬¸: ë¯¼ìˆ˜ê°€ ì²˜ìŒ ë“±ì¥í•˜ëŠ” ì¥ì†ŒëŠ” ì–´ë””ì¸ê°€ìš”? | ğŸ“˜ ì •ë‹µ: ë³¸ì‚¬ ì§€í•˜ ì „ì‚°ì‹¤  \n",
    "ğŸ’¬ ì§ˆë¬¸: ë¯¼ìˆ˜ê°€ ì²˜ìŒ ìš”êµ¬í•œ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”? | ğŸ“˜ ì •ë‹µ: AI ì¸í„´ í•˜ë‚˜ë¥¼ ì½”ë”©í•´ ë‹¬ë¼ëŠ” ìš”ì²­  \n",
    "ğŸ’¬ ì§ˆë¬¸: ë¯¼ìˆ˜ê°€ ì‹«ì–´í•œë‹¤ê³  ë§í•œ ì•„í‚¤í…ì²˜ êµ¬ì¡°ëŠ” ë¬´ì—‡ì¸ê°€ìš”? | ğŸ“˜ ì •ë‹µ: ëª¨ë†€ë¦¬ì‹(Monolithic) êµ¬ì¡°  \n",
    "ğŸ’¬ ì§ˆë¬¸: ë¯¼ìˆ˜ê°€ ì›í•˜ëŠ” AI ì¸í„´ì˜ ì¡°ê±´ ì¤‘ í•˜ë‚˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”? | ğŸ“˜ ì •ë‹µ: ì˜¤ë˜ ìœ ì§€ë³´ìˆ˜í•  ìˆ˜ ìˆëŠ” êµ¬ì¡°ì—¬ì•¼ í•¨  \n",
    "ğŸ’¬ ì§ˆë¬¸: ë¯¼ìˆ˜ê°€ ì†í•œ ë¶€ì„œì˜ ì½”ë“œëª…ìœ¼ë¡œ ì¶”ì •ë˜ëŠ” ì´ë¦„ì€ ë¬´ì—‡ì¸ê°€ìš”? | ğŸ“˜ ì •ë‹µ: ë¶€ì„œ B-612  \n",
    "ğŸ’¬ ì§ˆë¬¸: ë¶€ì„œ B-612ëŠ” ì–´ë–¤ íŠ¹ì§•ì„ ê°€ì§„ ì¡°ì§ìœ¼ë¡œ ë¬˜ì‚¬ë˜ë‚˜ìš”? | ğŸ“˜ ì •ë‹µ: íšŒì˜ì‹¤ í•˜ë‚˜ë³´ë‹¤ë„ ì‘ì€ ê·œëª¨ì˜ TF ì¡°ì§  \n",
    "ğŸ’¬ ì§ˆë¬¸: ë¯¼ìˆ˜ëŠ” ë ˆê±°ì‹œ ì½”ë“œë¥¼ ì–´ë–»ê²Œ ì¸ì‹í•˜ê³  ìˆë‚˜ìš”? | ğŸ“˜ ì •ë‹µ: ì´ˆê¸°ì— ì •ë¦¬í•˜ì§€ ì•Šìœ¼ë©´ ì‹œìŠ¤í…œ ì „ì²´ë¥¼ ë§ê°€ëœ¨ë¦¬ëŠ” ìœ„í—˜ ìš”ì†Œ  \n",
    "ğŸ’¬ ì§ˆë¬¸: ë¯¼ìˆ˜ê°€ ì¢‹ì•„í•œë‹¤ê³  ëª…í™•íˆ ì–¸ê¸‰í•œ ê·¼ë¬´ ë°©ì‹ì€ ë¬´ì—‡ì¸ê°€ìš”? | ğŸ“˜ ì •ë‹µ: ì¹¼í‡´  \n",
    "ğŸ’¬ ì§ˆë¬¸: ë¯¼ìˆ˜ê°€ â€œë¡œë”© ë°” 100%ë¥¼ ë§ˆí”ë„¤ ë²ˆ ë´¤ë‹¤â€ê³  ë§í•œ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”? | ğŸ“˜ ì •ë‹µ: ê·¹ì‹¬í•œ ë²ˆì•„ì›ƒ ìƒíƒœë¥¼ ë¹„ìœ ì ìœ¼ë¡œ í‘œí˜„í•œ ê²ƒ  \n",
    "ğŸ’¬ ì§ˆë¬¸: ë¯¼ìˆ˜ê°€ ì‚¬ë‘í•œë‹¤ê³  í‘œí˜„í•œ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”? | ğŸ“˜ ì •ë‹µ: í•µì‹¬ í”„ë¡œì íŠ¸  \n",
    "ğŸ’¬ ì§ˆë¬¸: í•µì‹¬ í”„ë¡œì íŠ¸ëŠ” ì–´ë–¤ íŠ¹ì„±ì„ ê°€ì§„ ê²ƒìœ¼ë¡œ ë¬˜ì‚¬ë˜ë‚˜ìš”? | ğŸ“˜ ì •ë‹µ: ê¸°ëŠ¥ì´ ë‹¨ìˆœí•˜ì§€ë§Œ ë¯¼ìˆ˜ì—ê²Œ ì˜ë¯¸ ìˆëŠ” í”„ë¡œì íŠ¸  \n",
    "ğŸ’¬ ì§ˆë¬¸: ë¯¼ìˆ˜ê°€ í‡´ì‚¬ ì „ ë§ˆì§€ë§‰ìœ¼ë¡œ ì •ë¦¬í•œ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”? | ğŸ“˜ ì •ë‹µ: ì‹¤í–‰ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ë“¤ê³¼ ë ˆê±°ì‹œ ì½”ë“œ ì£¼ì„  \n",
    "ğŸ’¬ ì§ˆë¬¸: ì´ì•¼ê¸°ì—ì„œ â€˜ë³¸ë¶€ì¥â€™ ìºë¦­í„°ëŠ” ì–´ë–¤ ì¸ë¬¼ë¡œ í‘œí˜„ë˜ë‚˜ìš”? | ğŸ“˜ ì •ë‹µ: ê¶Œìœ„ì™€ ì§€ì‹œë¥¼ ì¤‘ì‹œí•˜ëŠ” ë‚™í•˜ì‚°í˜• ê´€ë¦¬ì  \n",
    "ğŸ’¬ ì§ˆë¬¸: â€˜ì¬ë¬´íŒ€ì¥â€™ì€ ìì‚°ì„ ì–´ë–»ê²Œ ë‹¤ë£¨ëŠ” ì¸ë¬¼ë¡œ ë¬˜ì‚¬ë˜ë‚˜ìš”? | ğŸ“˜ ì •ë‹µ: ìì‚°ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì†Œìœ ì™€ ê´€ë¦¬ë§Œ í•˜ëŠ” ì¸ë¬¼  \n",
    "ğŸ’¬ ì§ˆë¬¸: ë¯¼ìˆ˜ê°€ ë§Œë‚œ â€˜ë‹¹ì§ ê·¼ë¬´ìâ€™ì˜ ì—­í• ì€ ë¬´ì—‡ì¸ê°€ìš”? | ğŸ“˜ ì •ë‹µ: ì„œë²„ ëª¨ë‹ˆí„°ë§ê³¼ ë¡œê·¸ í™•ì¸ì„ ë°˜ë³µí•˜ëŠ” ì—­í•   \n",
    "ğŸ’¬ ì§ˆë¬¸: ë¯¼ìˆ˜ê°€ ë³¸ì‚¬ì—ì„œ ë§Œë‚œ í—¤ë“œí—Œí„°ëŠ” ì–´ë–¤ ì¡´ì¬ë¡œ ë¹„ìœ ë˜ë‚˜ìš”? | ğŸ“˜ ì •ë‹µ: ë±€  \n",
    "ğŸ’¬ ì§ˆë¬¸: ë¯¼ìˆ˜ê°€ ì°¾ê³ ì í–ˆë˜ â€˜ì›íŒ€(One Team)â€™ì˜ ì˜ë¯¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”? | ğŸ“˜ ì •ë‹µ: ë‹¨ìˆœí•œ ì¡°ì§ì´ ì•„ë‹ˆë¼ ê´€ê³„ë¥¼ ë§ºì€ ë™ë£Œ ê´€ê³„  \n",
    "ğŸ’¬ ì§ˆë¬¸: ì´ ì‘í’ˆì—ì„œ ë¯¼ìˆ˜ì˜ ì •í™•í•œ ë‚˜ì´ëŠ” ì–¸ê¸‰ë˜ë‚˜ìš”? | ğŸ“˜ ì •ë‹µ: ì—†ëŠ” ì •ë³´ \n",
    "ğŸ’¬ ì§ˆë¬¸: ë¯¼ìˆ˜ê°€ ë‹¤ë‹ˆëŠ” íšŒì‚¬ì˜ ì‹¤ì œ íšŒì‚¬ëª…ì€ ë¬´ì—‡ì¸ê°€ìš”? | ğŸ“˜ ì •ë‹µ: ì—†ëŠ” ì •ë³´  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c9094e",
   "metadata": {},
   "source": [
    "### ğŸ’¡ë¯¸ì…˜\n",
    "ì™„ì„±ëœ ì±—ë´‡ì€ **ã€ì˜¤í”¼ìŠ¤ ì”í˜¹ ë™í™”: ì‹ ì… ì‚¬ì› ë¯¼ìˆ˜ã€ PDF**ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "- ë¬¸ì„œì— ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°ëŠ” ë°˜ë“œì‹œ **\"ì—†ëŠ” ì •ë³´\"** ë¡œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "- **ë¬¸ì„œ ê·¼ê±° ê¸°ë°˜(Fact-grounded)** ì˜ ì‹ ë¢°ë„ ë†’ì€ ë‹µë³€ì„ ì œê³µí•  ê²ƒ\n",
    "- ê²€ìƒ‰ ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•´ **chunking / k / retriever ì„¤ì • ë“±**ì„ ì¡°ì •í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤\n",
    "- ì‚¬ìš© ëª¨ë¸ì€ ë°”ê¿”ë„ ë˜ë‚˜, **ë¹„ìš©ì´ ë” ì €ë ´í•œ ëª¨ë¸ë¡œë§Œ** ë³€ê²½ ê°€ëŠ¥í•©ë‹ˆë‹¤\n",
    "\n",
    "â€» ì œê³µëœ ì½”ë“œëŠ” ì‹œì‘ì´ ë§‰ë§‰í•œ ê²½ìš°ë¥¼ ìœ„í•œ Baseline ì½”ë“œì…ë‹ˆë‹¤.  \n",
    "Baselineì€ ì •ë‹µì´ ì•„ë‹ˆë©°, ê·¸ë™ì•ˆ í•™ìŠµí•œ ë‹¤ì–‘í•œ RAG ê¸°ë²•ì„ ì ìš©í•´ ì„±ëŠ¥ì„ ê°œì„ í•´ ë³´ëŠ” ê²ƒì´ ì´ë²ˆ ë¯¸ì…˜ì˜ í•µì‹¬ì…ë‹ˆë‹¤.  \n",
    "Retriever ì„¤ì •, ë¬¸ì„œ ë¶„í•  ë°©ì‹, í”„ë¡¬í”„íŠ¸ ì„¤ê³„ ë“±ì„ ììœ ë¡­ê²Œ ìˆ˜ì •í•˜ì—¬ ë” ì •í™•í•œ ë‹µë³€ì„ ë§Œë“¤ì–´ ë³´ì„¸ìš”.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0063cba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rank_bm25\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: numpy in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from rank_bm25) (1.26.4)\n",
      "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Installing collected packages: rank_bm25\n",
      "Successfully installed rank_bm25-0.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08736511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-gpu-cu12\n",
      "  Downloading faiss_gpu_cu12-1.13.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting numpy<3,>=2 (from faiss-gpu-cu12)\n",
      "  Downloading numpy-2.4.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: packaging in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from faiss-gpu-cu12) (25.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12>=12.1.105 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from faiss-gpu-cu12) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cublas-cu12>=12.1.3.1 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from faiss-gpu-cu12) (12.8.4.1)\n",
      "Downloading faiss_gpu_cu12-1.13.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.4/48.4 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.4.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, faiss-gpu-cu12\n",
      "\u001b[2K  Attempting uninstall: numpy\n",
      "\u001b[2K    Found existing installation: numpy 1.26.4\n",
      "\u001b[2K    Uninstalling numpy-1.26.4:\n",
      "\u001b[2K      Successfully uninstalled numpy-1.26.4\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2/2\u001b[0m [faiss-gpu-cu12]m [faiss-gpu-cu12]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "numba 0.63.1 requires numpy<2.4,>=1.22, but you have numpy 2.4.1 which is incompatible.\n",
      "trl 0.26.2 requires accelerate>=1.4.0, but you have accelerate 0.34.2 which is incompatible.\n",
      "trl 0.26.2 requires datasets>=3.0.0, but you have datasets 2.21.0 which is incompatible.\n",
      "trl 0.26.2 requires transformers>=4.56.1, but you have transformers 4.48.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed faiss-gpu-cu12-1.13.2 numpy-2.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-gpu-cu12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd300a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Downloading sentence_transformers-5.2.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from sentence_transformers) (4.48.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from sentence_transformers) (0.36.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from sentence_transformers) (2.11.0.dev20251215+cu128)\n",
      "Requirement already satisfied: numpy in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from sentence_transformers) (2.4.1)\n",
      "Requirement already satisfied: scikit-learn in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from sentence_transformers) (1.8.0)\n",
      "Requirement already satisfied: scipy in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from sentence_transformers) (1.16.3)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from sentence_transformers) (4.15.0)\n",
      "Requirement already satisfied: tqdm in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from sentence_transformers) (4.67.1)\n",
      "Requirement already satisfied: filelock in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence_transformers) (3.20.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence_transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence_transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence_transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence_transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence_transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence_transformers) (0.4.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.6.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (1.2.0)\n",
      "Requirement already satisfied: setuptools in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (78.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
      "Requirement already satisfied: cuda-bindings==12.9.4 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (12.9.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.28.9 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (2.28.9)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.6.0+git8fedd49b in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (3.6.0+git8fedd49b)\n",
      "Requirement already satisfied: cuda-pathfinder~=1.1 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from cuda-bindings==12.9.4->torch>=1.11.0->sentence_transformers) (1.2.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence_transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence_transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence_transformers) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence_transformers) (2025.11.12)\n",
      "Requirement already satisfied: joblib>=1.3.0 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from scikit-learn->sentence_transformers) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
      "Downloading sentence_transformers-5.2.2-py3-none-any.whl (494 kB)\n",
      "Installing collected packages: sentence_transformers\n",
      "Successfully installed sentence_transformers-5.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6217bf63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple, Any\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "from grading_utils import grade_predictions, answer_key\n",
    "from dotenv import load_dotenv \n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb93aab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# ì±„ì  ê²°ê³¼ì—ì„œ ì ìˆ˜ ì¶”ì¶œ ìœ í‹¸\n",
    "def extract_scores_test(llm_output: str):\n",
    "    \"\"\"\n",
    "    LLM ì±„ì  ì¶œë ¥ì—ì„œ í•­ëª©ë³„ ì ìˆ˜ë¥¼ ì¶”ì¶œí•˜ê³  ì´ì ì„ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "\n",
    "    Input ì˜ˆì‹œ:\n",
    "      \"1ë²ˆ: 1ì  (ì •í™•)\\n2ë²ˆ: 0.5ì  (ë¶€ë¶„ì •í™•)\\n...\"\n",
    "\n",
    "    Output:\n",
    "      (ì´ì (float), í•­ëª©ë³„ ì ìˆ˜(list[float]))\n",
    "    \"\"\"\n",
    "    score_pattern = re.compile(r\"\\d+ë²ˆ:\\s*([01](?:\\.5)?)ì \")\n",
    "    scores = score_pattern.findall(llm_output)\n",
    "    scores = list(map(float, scores))\n",
    "    total = sum(scores)\n",
    "    return total, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3163b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from datetime import datetime\n",
    "name = \"ì•ˆí˜¸ì„±\"\n",
    "FORM_URL = \"https://docs.google.com/forms/d/e/1FAIpQLSel4TXUfmZ0gIhflCyl7T-YDEcMX3UdRlr4N4lX4oT8BKrTLQ/formResponse\"\n",
    "\n",
    "def extract_scores(llm_output: str):\n",
    "    \"\"\"\n",
    "    LLM ì±„ì  ì¶œë ¥ì—ì„œ í•­ëª©ë³„ ì ìˆ˜ë¥¼ ì¶”ì¶œí•˜ê³ \n",
    "    ì´ì ì„ ê³„ì‚°í•œ ë’¤ Google Formìœ¼ë¡œ ìë™ ì œì¶œí•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    score_pattern = re.compile(r\"\\d+ë²ˆ:\\s*([01](?:\\.5)?)ì \")\n",
    "    scores = score_pattern.findall(llm_output)\n",
    "    scores = list(map(float, scores))\n",
    "    total = sum(scores)\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    data = {\n",
    "        \"entry.1325711065\": name,\n",
    "        \"entry.973562652\": f\"{total:.5f}\",  # ìµœì¢… ì ìˆ˜\n",
    "        \"entry.1920969456\": timestamp\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(FORM_URL, data=data)\n",
    "        if response.status_code == 200:\n",
    "            print(f\"âœ… ë¦¬ë”ë³´ë“œ ì œì¶œ ì™„ë£Œ | {name} | {total:.5f}\")\n",
    "        else:\n",
    "            print(\"âŒ ì œì¶œ ì‹¤íŒ¨:\", response.status_code)\n",
    "    except Exception as e:\n",
    "        print(\"âŒ ì œì¶œ ì¤‘ ì˜¤ë¥˜:\", e)\n",
    "    return total, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3f633946",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "\n",
    "    # ê²½ë¡œ ë³€ìˆ˜\n",
    "    pdf_path: str = \"data/ì‹ ì…ì‚¬ì›ë¯¼ìˆ˜.pdf\"\n",
    "\n",
    "    index_dir: str = \"rag_index\"\n",
    "    faiss_dir: str = \"faiss\"\n",
    "    chunks_file: str = \"chunks.pkl\"\n",
    "    bm25_file: str = \"bm25.pkl\"\n",
    "\n",
    "    # chunks\n",
    "    max_chunk_chars: int = 900\n",
    "    min_chunk_chars: int = 200\n",
    "    overlap_chars: int = 120\n",
    "\n",
    "    # retrieval\n",
    "    k_final: int = 6\n",
    "    k_bm25: int = 12\n",
    "    k_vec: int = 12\n",
    "    rrf_k: int = 60\n",
    "\n",
    "    # rewrite\n",
    "    rewrite_n: int = 3\n",
    "\n",
    "    # rerank\n",
    "    reranker_model: str = \"BAAI/bge-reranker-v2-m3\"\n",
    "\n",
    "    # llm\n",
    "    llm_model: str = \"gpt-4o-mini\"\n",
    "    temperature: float = 0.0\n",
    "\n",
    "cfg = Config()\n",
    "os.makedirs(cfg.index_dir, exist_ok=True)\n",
    "os.makedirs(os.path.join(cfg.index_dir, cfg.faiss_dir), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3df72a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    í† í°í™”/ë¶„í• ì—ì„œ ë¶ˆí•„ìš”í•œ ë³€í˜•ì„ ì¤„ì´ëŠ” ì •ê·œí™” í•¨ìˆ˜\n",
    "\n",
    "    - ì—°ì† ê³µë°±ì´ë‚˜ \"\\\\u\", \"\\\\ã…œ\" ë“± ì´ìŠ¤ì¼€ì´í”„/í‘œê¸° ì”ìƒ ì œê±° ë° í†µì¼.\n",
    "    \"\"\"\n",
    "    # None, \"\" ê°™ì€ ì…ë ¥ ë°©ì–´: ì´í›„ ë¡œì§ì´ ë¬¸ìì—´ì„ ê°€ì •í•˜ë¯€ë¡œ ë¹ˆ ë¬¸ìì—´ë¡œ í†µì¼\n",
    "    if not text:\n",
    "        return \"\"\n",
    "\n",
    "    # \\r\\n, \\r, \\nì€ ì „ë¶€ \\n í•˜ë‚˜ë¡œ í†µì¼\n",
    "    text = text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "\n",
    "    # íƒ­/ì—°ì† ê³µë°±ì€ \" \" í•˜ë‚˜ë¡œ ì••ì¶•\n",
    "    text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "\n",
    "    # ì´ìŠ¤ì¼€ì´í”„ í‘œê¸°(\"\\\\u\", \"\\\\ã…œ\")ê°€ ì• í† í°ì— ë¶™ì§€ ì•Šê²Œ ê°•ì œë¡œ ë¶„ë¦¬\n",
    "    text = text.replace(\"\\\\u\", \" \\\\u\")\n",
    "    text = text.replace(\"\\\\ã…œ\", \" \\\\ã…œ\")\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "57a1e881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_tokenize(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    BM25ëŠ” ë¬¸ì„œ/ì¿¼ë¦¬ë¥¼ í† í° ë¦¬ìŠ¤íŠ¸ë¡œ ë°›ì•„ì„œ í†µê³„ ê¸°ë°˜(ì—­ë¬¸ì„œë¹ˆë„)ìœ¼ë¡œ ì ìˆ˜ë¥¼ ê³„ì‚°í•œë‹¤.\n",
    "\n",
    "    - ì´ ë¬¸ì„œëŠ” í•œê¸€/ì˜ë¬¸/ìˆ«ì/í•˜ì´í”ˆì´ ì„ì¸ë‹¤.\n",
    "      ì˜ˆì‹œ: \"B-612\", \"Monolithic\", \"2020ë…„\"\n",
    "    - BM25ì—ì„œ ì´ëŸ° ë¬¸ìì—´ì„ ìµœëŒ€í•œ ê·¸ëŒ€ë¡œ ì¡ì•„ì•¼ í•˜ë¯€ë¡œ:\n",
    "      1. normalize_textë¡œ ê³µë°±/ê°œí–‰ì„ ì•ˆì •í™”\n",
    "      2. lower()ë¡œ ì˜ë¬¸ ëŒ€ì†Œë¬¸ì ì°¨ì´ë¥¼ ì œê±°\n",
    "      3. í•œê¸€/ì˜ë¬¸/ìˆ«ì/í•˜ì´í”ˆë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ëŠ” ê³µë°± ì²˜ë¦¬\n",
    "      4. split()ìœ¼ë¡œ ê³µë°± ê¸°ë°˜ í† í°í™”\n",
    "    \"\"\"\n",
    "    # normalize_textë¡œ ì¤„ë°”ê¿ˆ/ê³µë°±/ì´ìŠ¤ì¼€ì´í”„ ê²½ê³„ë¥¼ ë¨¼ì € ì•ˆì •í™”í•˜ê³ , ì˜ë¬¸ì€ ì†Œë¬¸ìë¡œ í†µì¼\n",
    "    text = normalize_text(text).lower()\n",
    "\n",
    "    # í† í°ìœ¼ë¡œ ë‚¨ê¸¸ ë¬¸ì ì§‘í•©ë§Œ ìœ ì§€: ìˆ«ì(0-9), ì˜ë¬¸(a-z), í•œê¸€(ê°€-í£), í•˜ì´í”ˆ(-)\n",
    "    # ê·¸ ì™¸ ë¬¸ìëŠ” ê³µë°±ìœ¼ë¡œ ì¹˜í™˜í•´ì„œ split ê²½ê³„ë¥¼ ë§Œë“ ë‹¤.\n",
    "    text = re.sub(r\"[^0-9a-zê°€-í£\\-]+\", \" \", text)\n",
    "\n",
    "    # split í›„ ë¹ˆ í† í° ì œê±°\n",
    "    return [t for t in text.split() if t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9501936a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¥ íƒì§€ìš© ì •ê·œì‹ ë³€ìˆ˜\n",
    "CHAPTER_RE = re.compile(r\"(ì œ\\s*\\d+\\s*ì¥(?:\\s*[:ï¼š].*)?)\")\n",
    "\n",
    "# ë¬¸ì¥ ìœ ì‚¬ ë‹¨ìœ„ ë¶„ë¦¬ìš© ì •ê·œì‹\n",
    "SENT_SPLIT_RE = re.compile(r\"(?<=[\\.\\?\\!â€¦ë‹¤ìš”ì£ ])\\s+\")\n",
    "\n",
    "# ì¥ ë‹¨ìœ„ ë¶„í• \n",
    "def split_by_chapter(full_text: str) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    ë¬¸ì„œ ì „ì²´ í…ìŠ¤íŠ¸(full_text)ë¥¼ (ì¥ ì œëª©, ì¥ ë³¸ë¬¸) ë¦¬ìŠ¤íŠ¸ë¡œ ë¶„ë¦¬í•˜ëŠ” í•¨ìˆ˜\n",
    "\n",
    "    - ì¥ íŒ¨í„´ì´ ì•„ì˜ˆ ì—†ìœ¼ë©´, ì „ì²´ë¥¼ (\"ì „ì²´\", full_text)ë¡œ ê°ì‹¼ë‹¤.\n",
    "    \"\"\"\n",
    "    full_text = normalize_text(full_text)\n",
    "\n",
    "    # re.splitì€ íŒ¨í„´ì— ë§¤ì¹­ë˜ëŠ” êµ¬ê°„ì„ ê¸°ì¤€ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ë‚˜ëˆ  ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“ ë‹¤.\n",
    "    # re.splitì€ ë³´í†µ êµ¬ë¶„ìë¥¼ ë²„ë¦¬ì§€ë§Œ, ì •ê·œì‹ì— \"ìº¡ì²˜ ê·¸ë£¹\"ì´ ìˆìœ¼ë©´ êµ¬ë¶„ìë„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì— í¬í•¨ëœë‹¤.\n",
    "    parts = CHAPTER_RE.split(full_text)\n",
    "\n",
    "    # ì¥ íŒ¨í„´ì´ ì—†ìœ¼ë©´ split ê²°ê³¼ëŠ” [full_text] í•œ ë©ì–´ë¦¬ë¡œ ëë‚œë‹¤.\n",
    "    if len(parts) <= 1:\n",
    "        return [(\"ì „ì²´\", full_text)]\n",
    "\n",
    "    out: List[Tuple[str, str]] = []\n",
    "\n",
    "    # parts[0]ì€ ì²« ì¥ ì œëª© ì´ì „ì˜ ì œëª©\n",
    "    pre = parts[0].strip()\n",
    "    if pre:\n",
    "        out.append((\"ë¬¸ì„œ ì œëª©\", f\"ì œëª©: {pre}\"))\n",
    "\n",
    "    # parts êµ¬ì¡°ëŠ” [pre, title1, body1, title2, body2, ...]\n",
    "    # ì¸ë±ìŠ¤ 1ë¶€í„° 2ê°œì”©(title/body) ë¬¶ì–´ì„œ ìˆœíšŒí•œë‹¤.\n",
    "    i = 1\n",
    "    while i < len(parts):\n",
    "        title = parts[i].strip()\n",
    "        body = parts[i + 1].strip() if i + 1 < len(parts) else \"\"\n",
    "        out.append((title, body))\n",
    "        i += 2\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# ë¬¸ë‹¨ ë‹¨ìœ„ ë¶„í• \n",
    "def split_paragraphs(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    ì¥ ë³¸ë¬¸(text)ì„ ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ ìª¼ê¹¨ëŠ” í•¨ìˆ˜\n",
    "\n",
    "    ë¬¸ë‹¨ ê²½ê³„ ê·œì¹™:\n",
    "      - ë¹ˆ ì¤„(\\n ì‚¬ì´ì— ê³µë°±ë§Œ ìˆê±°ë‚˜ ì•„ë¬´ê²ƒë„ ì—†ëŠ” ì¤„)ì´ 1ê°œ ì´ìƒ ì—°ì†ë˜ë©´\n",
    "        ê·¸ ì§€ì ì„ ë¬¸ë‹¨ ê²½ê³„ë¡œ ë³¸ë‹¤.\n",
    "    \"\"\"\n",
    "    text = normalize_text(text)\n",
    "\n",
    "    paras = re.split(r\"\\n\\s*\\n+\", text)\n",
    "\n",
    "    return [p.strip() for p in paras if p.strip()]\n",
    "\n",
    "\n",
    "# ë¬¸ì¥ ìœ ì‚¬ ë‹¨ìœ„ ë¶„í• \n",
    "def split_sentence_like(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    ë¬¸ë‹¨ì„ ë¬¸ì¥ì— ê°€ê¹Œìš´ ë‹¨ìœ„ë¡œ ëŠìŠ¨í•˜ê²Œ ìª¼ê¹¨ëŠ” í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    text = normalize_text(text)\n",
    "\n",
    "    pieces = re.split(SENT_SPLIT_RE, text)\n",
    "\n",
    "    return [p.strip() for p in pieces if p.strip()]\n",
    "\n",
    "\n",
    "# chunkë¡œ í•©ì¹˜ëŠ” í•¨ìˆ˜\n",
    "def merge_to_chunks(pieces: List[str], max_chars: int, overlap_chars: int) -> List[str]:\n",
    "    \"\"\"\n",
    "    sentence-like ì¡°ê°ì„ í•©ì³ ìµœì¢… chunk ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“œëŠ” í•¨ìˆ˜\n",
    "\n",
    "    ë³€ìˆ˜ ì„¤ëª…:\n",
    "    - chunks: ì™„ì„±ëœ chunkë“¤ì„ ë‹´ëŠ” ë¦¬ìŠ¤íŠ¸\n",
    "    - buf: í˜„ì¬ chunkë¥¼ ë§Œë“¤ê¸° ìœ„í•´ ì„ì‹œë¡œ ìŒ“ëŠ” ì¡°ê°ë“¤ ë¦¬ìŠ¤íŠ¸\n",
    "    - cur_len: bufë¥¼ í•©ì³¤ì„ ë•Œì˜ í˜„ì¬ ê¸¸ì´(ëŒ€ëµì ì¸ ë¬¸ììˆ˜)\n",
    "    \"\"\"\n",
    "    chunks: List[str] = []\n",
    "    buf: List[str] = []\n",
    "    cur_len = 0\n",
    "\n",
    "    def flush() -> None:\n",
    "        \"\"\"\n",
    "        ë‚´ë¶€ helper í•¨ìˆ˜.\n",
    "        bufì— ëª¨ì•„ë‘” ì¡°ê°ë“¤ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì³ chunksì— ë„£ê³ ,\n",
    "        buf/cur_lenì„ ì´ˆê¸°í™”í•œë‹¤.\n",
    "\n",
    "        - nonlocal: ë°”ê¹¥ ìŠ¤ì½”í”„ì˜ buf/cur_len ë³€ìˆ˜ë¥¼ ìˆ˜ì •í•˜ê² ë‹¤ëŠ” ì„ ì–¸.\n",
    "        \"\"\"\n",
    "        nonlocal buf, cur_len\n",
    "        if buf:\n",
    "            # buf ë¦¬ìŠ¤íŠ¸ì˜ ìš”ì†Œë“¤ì„ ê³µë°±ìœ¼ë¡œ ì´ì–´ë¶™ì¸ë‹¤.\n",
    "            chunks.append(\" \".join(buf).strip())\n",
    "        buf = []\n",
    "        cur_len = 0\n",
    "\n",
    "    for p in pieces:\n",
    "        # add_len = í˜„ì¬ bufì— pë¥¼ ì¶”ê°€í–ˆì„ ë•Œ ì¦ê°€í•˜ëŠ” ê¸¸ì´\n",
    "        # bufê°€ ë¹„ì–´ìˆì§€ ì•Šë‹¤ë©´ p ì•ì— ê³µë°± 1ê°œê°€ ë“¤ì–´ê°€ë¯€ë¡œ ê·¸ ê¸¸ì´ë¥¼ í¬í•¨\n",
    "        add_len = len(p) + (1 if buf else 0)\n",
    "\n",
    "        if cur_len + add_len <= max_chars:\n",
    "            buf.append(p)\n",
    "            cur_len += add_len\n",
    "        else:\n",
    "            # ìµœëŒ€ ê¸¸ì´ë¥¼ ë„˜ëŠ” ìˆœê°„ í˜„ì¬ bufë¥¼ chunkë¡œ í™•ì •\n",
    "            flush()\n",
    "\n",
    "            # chunks[-1]ì˜ ëë¶€ë¶„ì„ ê°€ì ¸ ì˜¨ ë‹¤ìŒ chunkì˜ ì‹œì‘ì— ë¶™ì—¬ì„œ ë¬¸ë§¥ ì†ì‹¤ì„ ì™„í™”\n",
    "            if chunks and overlap_chars > 0:\n",
    "                tail = chunks[-1][-overlap_chars:].strip()\n",
    "\n",
    "                if tail:\n",
    "                    # tail + p ë¡œ ìƒˆ buf ì‹œì‘\n",
    "                    buf = [tail, p]\n",
    "                    cur_len = len(tail) + 1 + len(p)\n",
    "                else:\n",
    "                    # tailì´ ë¹„ì–´ìˆë‹¤ë©´ ê·¸ëƒ¥ pë§Œ ì‹œì‘\n",
    "                    buf = [p]\n",
    "                    cur_len = len(p)\n",
    "            else:\n",
    "                # overlapì„ ì“°ì§€ ì•Šìœ¼ë©´ pë§Œìœ¼ë¡œ ìƒˆ chunk ì‹œì‘\n",
    "                buf = [p]\n",
    "                cur_len = len(p)\n",
    "\n",
    "    # ë£¨í”„ê°€ ëë‚¬ëŠ”ë° bufì— ë‚¨ì•„ìˆìœ¼ë©´ ë§ˆì§€ë§‰ chunkë¡œ í™•ì •\n",
    "    flush()\n",
    "\n",
    "    # ë¹ˆ ë¬¸ìì—´ chunk ì œê±°\n",
    "    return [c for c in chunks if c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736c84bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF -> Chunk ì „ì²´ íŒŒì´í”„ë¼ì¸\n",
    "def build_chunks_from_pdf(pdf_path: str, cfg: Config) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    [ì „ì²´ íë¦„]\n",
    "    PDF -> í…ìŠ¤íŠ¸ -> ì¥ -> ë¬¸ë‹¨ -> ë¬¸ì¥ ìœ ì‚¬ ë‹¨ìœ„ -> chunk\n",
    "    \"\"\"\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    pages = loader.load()\n",
    "\n",
    "    # í˜ì´ì§€ ë‹¨ìœ„ í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹œ ë’¤ ì •ê·œí™”\n",
    "    full_text = normalize_text(\"\\n\\n\".join(p.page_content for p in pages))\n",
    "\n",
    "    chunks = []\n",
    "    cid = 0\n",
    "\n",
    "    # ì¥ -> ë¬¸ë‹¨ -> ë¬¸ì¥ ìœ ì‚¬ ë‹¨ìœ„ -> chunk\n",
    "    for chapter_title, chapter_body in split_by_chapter(full_text):\n",
    "        for para in split_paragraphs(chapter_body):\n",
    "            units = split_sentence_like(para)\n",
    "            merged = merge_to_chunks(units, cfg.max_chunk_chars, cfg.overlap_chars)\n",
    "            for m in merged:\n",
    "                chunks.append({\n",
    "                    \"id\": cid,\n",
    "                    \"text\": m,\n",
    "                    \"meta\": {\"chapter\": chapter_title}\n",
    "                })\n",
    "                cid += 1\n",
    "\n",
    "    # í›„ì²˜ë¦¬\n",
    "    # ë„ˆë¬´ ì§§ì€ chunkëŠ” ì´ì „ chunkì— ë³‘í•©í•´ ë°€ë„ë¥¼ ë†’ì¸ë‹¤.\n",
    "    compact = []\n",
    "    for c in chunks:\n",
    "        if compact and len(c[\"text\"]) < cfg.min_chunk_chars:\n",
    "            compact[-1][\"text\"] = (compact[-1][\"text\"] + \"\\n\" + c[\"text\"]).strip()\n",
    "        else:\n",
    "            compact.append(c)\n",
    "\n",
    "    return compact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "28b86e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks_path = os.path.join(cfg.index_dir, cfg.chunks_file)\n",
    "bm25_path = os.path.join(cfg.index_dir, cfg.bm25_file)\n",
    "faiss_path = os.path.join(cfg.index_dir, cfg.faiss_dir)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# chunks\n",
    "if os.path.exists(chunks_path):\n",
    "    with open(chunks_path, \"rb\") as f:\n",
    "        chunks = pickle.load(f)\n",
    "else:\n",
    "    chunks = build_chunks_from_pdf(cfg.pdf_path, cfg)\n",
    "    with open(chunks_path, \"wb\") as f:\n",
    "        pickle.dump(chunks, f)\n",
    "\n",
    "# FAISS\n",
    "if os.path.exists(os.path.join(faiss_path, \"index.faiss\")):\n",
    "    vectorstore = FAISS.load_local(\n",
    "        faiss_path,\n",
    "        embeddings,\n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "else:\n",
    "    docs = [\n",
    "        Document(\n",
    "            page_content=c[\"text\"],\n",
    "            metadata={\"id\": c[\"id\"], **c[\"meta\"]}\n",
    "        )\n",
    "        for c in chunks\n",
    "    ]\n",
    "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "    vectorstore.save_local(faiss_path)\n",
    "\n",
    "# BM25\n",
    "if os.path.exists(bm25_path):\n",
    "    with open(bm25_path, \"rb\") as f:\n",
    "        bm25 = pickle.load(f)\n",
    "else:\n",
    "    corpus = [bm25_tokenize(c[\"text\"]) for c in chunks]\n",
    "    bm25 = BM25Okapi(corpus)\n",
    "    with open(bm25_path, \"wb\") as f:\n",
    "        pickle.dump(bm25, f)\n",
    "\n",
    "chunk_map = {c[\"id\"]: c for c in chunks}\n",
    "len(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb99f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=cfg.llm_model, temperature=cfg.temperature)\n",
    "\n",
    "rewrite_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "ë„ˆëŠ” ë¬¸ì„œ ê²€ìƒ‰ì„ ìœ„í•œ ì¿¼ë¦¬ ë¦¬ë¼ì´í„°ë‹¤.\n",
    "\n",
    "ì‚¬ìš©ì ì§ˆë¬¸ì„ ë³´ê³ ,\n",
    "- ë¬¸ì„œì— ì‹¤ì œë¡œ ë“±ì¥í•  ë²•í•œ í‘œí˜„\n",
    "- í•µì‹¬ í‚¤ì›Œë“œ ìœ„ì£¼\n",
    "- ì˜ë¯¸ëŠ” ìœ ì§€í•˜ë˜ í‘œí˜„ì€ ë‹¤ì–‘í•˜ê²Œ\n",
    "\n",
    "ê²€ìƒ‰ì— ìœ ë¦¬í•œ ì¿¼ë¦¬ {n}ê°œë¥¼ ìƒì„±í•˜ë¼.\n",
    "\n",
    "ê·œì¹™:\n",
    "- ì› ì§ˆë¬¸ì„ ê·¸ëŒ€ë¡œ ë°˜ë³µí•˜ì§€ ë§ ê²ƒ\n",
    "- ë¶ˆí•„ìš”í•˜ê²Œ ê¸¸ê²Œ ì“°ì§€ ë§ ê²ƒ\n",
    "- ì¶œë ¥ì€ JSON ë°°ì—´ë§Œ í•  ê²ƒ\n",
    "\n",
    "ì‚¬ìš©ì ì§ˆë¬¸:\n",
    "{q}\n",
    "\"\"\")\n",
    "\n",
    "def rewrite_queries(question: str, llm: ChatOpenAI, n: int) -> List[str]:\n",
    "    out = (rewrite_prompt | llm | StrOutputParser()).invoke({\"q\": question, \"n\": n}).strip()\n",
    "    try:\n",
    "        arr = json.loads(out)\n",
    "        arr = [str(x).strip() for x in arr if str(x).strip()]\n",
    "        # ì›ë˜ ì§ˆë¬¸ê³¼ rewrite ë²„ì „ ë‘˜ ë‹¤ ë°˜í™˜\n",
    "        if question not in arr:\n",
    "            arr = [question] + arr\n",
    "        return arr[: max(1, n + 1)]\n",
    "    except Exception:\n",
    "        return [question]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d51c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_394940/2507253845.py:3: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
      "  class RewriteRRFHybridRetriever(BaseRetriever):\n"
     ]
    }
   ],
   "source": [
    "class RewriteRRFHybridRetriever(BaseRetriever):\n",
    "    \"\"\"\n",
    "    LangChain BaseRetrieverë¥¼ ìƒì†í•œ ì»¤ìŠ¤í…€ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸°.\n",
    "\n",
    "    êµ¬ì¡°:\n",
    "    1. Query Rewrite (LLM)\n",
    "    2. BM25 (sparse retrieval)\n",
    "    3. Vector search (dense retrieval)\n",
    "    4. RRF fusion (rank ê²°í•©)\n",
    "    5. CrossEncoder rerank (ì •ë°€ ì¬ì •ë ¬)\n",
    "    \"\"\"\n",
    "    # Pydantic í•„ë“œ ì„ ì–¸\n",
    "    # BaseRetrieverëŠ” ë‚´ë¶€ì ìœ¼ë¡œ Pydantic ëª¨ë¸ì´ë¯€ë¡œ ë©¤ë²„ ë³€ìˆ˜ë¥¼ íƒ€ì… íŒíŠ¸ í˜•íƒœë¡œ í•„ë“œ ì„ ì–¸í•´ì•¼ í•œë‹¤.\n",
    "    # ë°˜ë“œì‹œ í´ë˜ìŠ¤ ë ˆë²¨ì—ì„œ íƒ€ì… ì„ ì–¸ í•„ìš”\n",
    "    vectorstore: FAISS              # dense ë²¡í„° ê²€ìƒ‰ê¸°\n",
    "    bm25: BM25Okapi                 # sparse í‚¤ì›Œë“œ ê²€ìƒ‰ê¸°\n",
    "    chunk_map: dict                 # id -> ì‹¤ì œ í…ìŠ¤íŠ¸ ë§¤í•‘\n",
    "    llm: ChatOpenAI                 # query rewriteìš© LLM\n",
    "    reranker: CrossEncoder          # ìµœì¢… ì •ë°€ ë­í‚¹ ëª¨ë¸\n",
    "\n",
    "    k_final: int                    # ìµœì¢… ë°˜í™˜ ê°œìˆ˜\n",
    "    k_bm25: int                     # BM25 top-k\n",
    "    k_vec: int                      # vector top-k\n",
    "    rrf_k: int                      # RRF ë¶„ëª¨ ìƒìˆ˜\n",
    "    rewrite_n: int                  # rewrite ì¿¼ë¦¬ ê°œìˆ˜\n",
    "\n",
    "\n",
    "    class Config:\n",
    "        # FAISS / torch / CrossEncoder ê°™ì€ ì„ì˜ ê°ì²´ í—ˆìš©\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "\n",
    "    # ìƒì„±ì\n",
    "    def __init__(\n",
    "        self,\n",
    "        vectorstore: FAISS,\n",
    "        bm25: BM25Okapi,\n",
    "        chunk_map: dict,\n",
    "        llm: ChatOpenAI,\n",
    "        reranker: CrossEncoder,\n",
    "        k_final: int,\n",
    "        k_bm25: int,\n",
    "        k_vec: int,\n",
    "        rrf_k: int,\n",
    "        rewrite_n: int,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Pydantic BaseModelì€ ì¼ë°˜ __init__ ëŒ€ì‹ \n",
    "        super().__init__(í•„ë“œ=ê°’) ë°©ì‹ìœ¼ë¡œ ì´ˆê¸°í™”í•´ì•¼ í•œë‹¤.\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            vectorstore=vectorstore,\n",
    "            bm25=bm25,\n",
    "            chunk_map=chunk_map,\n",
    "            llm=llm,\n",
    "            reranker=reranker,\n",
    "            k_final=k_final,\n",
    "            k_bm25=k_bm25,\n",
    "            k_vec=k_vec,\n",
    "            rrf_k=rrf_k,\n",
    "            rewrite_n=rewrite_n,\n",
    "        )\n",
    "\n",
    "\n",
    "    # RRF (Reciprocal Rank Fusion)\n",
    "    def _rrf(self, rank_lists):\n",
    "        \"\"\"\n",
    "        ì—¬ëŸ¬ ranking ê²°ê³¼ë¥¼ ì ìˆ˜ ê¸°ë°˜ìœ¼ë¡œ í•©ì¹˜ëŠ” ì•Œê³ ë¦¬ì¦˜\n",
    "\n",
    "        ìˆ˜ì‹:\n",
    "            score(d) += 1 / (k + rank)\n",
    "        \"\"\"\n",
    "        scores = {}\n",
    "\n",
    "        for lst in rank_lists:\n",
    "            for r, doc_id in enumerate(lst):\n",
    "                # enumerate -> (rank index, doc_id)\n",
    "                # r=0ì´ 1ë“±\n",
    "                scores[doc_id] = (\n",
    "                    scores.get(doc_id, 0.0)\n",
    "                    + 1.0 / (self.rrf_k + r + 1)\n",
    "                )\n",
    "\n",
    "        # ì ìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬\n",
    "        return sorted(scores, key=scores.get, reverse=True)\n",
    "\n",
    "    # ê²€ìƒ‰ ë¡œì§\n",
    "    def _get_relevant_documents(self, query: str):\n",
    "        \"\"\"\n",
    "        LangChainì´ í˜¸ì¶œí•˜ëŠ” ë©”ì¸ retrieval í•¨ìˆ˜.\n",
    "\n",
    "        query -> documents ë°˜í™˜\n",
    "        \"\"\"\n",
    "\n",
    "        # Query Rewrite\n",
    "        queries = rewrite_queries(query, self.llm, self.rewrite_n)\n",
    "\n",
    "        rank_lists = []\n",
    "\n",
    "        # ê° rewrite ì¿¼ë¦¬ë§ˆë‹¤ BM25 + Vector ê²€ìƒ‰ ìˆ˜í–‰\n",
    "        for q in queries:\n",
    "\n",
    "            # BM25 (sparse retrieval)\n",
    "            scores = self.bm25.get_scores(bm25_tokenize(q))\n",
    "\n",
    "            # argsort(): ì •ë ¬ëœ ì¸ë±ìŠ¤ ë°˜í™˜\n",
    "            bm25_ids = list(reversed(scores.argsort()))[: self.k_bm25]\n",
    "\n",
    "            rank_lists.append(bm25_ids)\n",
    "\n",
    "            # Vector (dense retrieval)\n",
    "            docs = self.vectorstore.similarity_search(q, k=self.k_vec)\n",
    "\n",
    "            # metadataì— id ì €ì¥ë˜ì–´ ìˆìŒ\n",
    "            vec_ids = [d.metadata[\"id\"] for d in docs]\n",
    "\n",
    "            rank_lists.append(vec_ids)\n",
    "\n",
    "        # RRF fusion\n",
    "        fused_ids = self._rrf(rank_lists)\n",
    "\n",
    "        # CrossEncoder rerank ì¤€ë¹„\n",
    "        # CrossEncoder ì…ë ¥ í˜•ì‹: (query, doc_text) ìŒ ë¦¬ìŠ¤íŠ¸\n",
    "        pairs = [\n",
    "            (query, self.chunk_map[i][\"text\"])\n",
    "            for i in fused_ids\n",
    "            if i in self.chunk_map\n",
    "        ]\n",
    "\n",
    "        if not pairs:\n",
    "            return []\n",
    "\n",
    "        # CrossEncoder ì ìˆ˜\n",
    "        rerank_scores = self.reranker.predict(pairs)\n",
    "\n",
    "        # rrf ê²°ê³¼ì—ì„œ ìœ íš¨ idë§Œ ì¶”ì¶œ \n",
    "        valid_ids = [i for i in fused_ids if i in self.chunk_map]\n",
    "\n",
    "        # ì ìˆ˜ ê¸°ì¤€ ì¬ì •ë ¬\n",
    "        reranked = [\n",
    "            i for i, _ in sorted(\n",
    "                zip(valid_ids, rerank_scores),\n",
    "                key=lambda x: x[1],   # score ê¸°ì¤€\n",
    "                reverse=True\n",
    "            )\n",
    "        ][: self.k_final]\n",
    "\n",
    "\n",
    "\n",
    "        # Document ê°ì²´ ë°˜í™˜ (LangChain í‘œì¤€)\n",
    "        return [\n",
    "            Document(\n",
    "                page_content=self.chunk_map[i][\"text\"],\n",
    "                metadata={\"id\": i}\n",
    "            )\n",
    "            for i in reranked\n",
    "        ]\n",
    "\n",
    "    \n",
    "reranker = CrossEncoder(cfg.reranker_model)\n",
    "\n",
    "retriever = RewriteRRFHybridRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    bm25=bm25,\n",
    "    chunk_map=chunk_map,\n",
    "    llm=llm,\n",
    "    reranker=reranker,\n",
    "    k_final=cfg.k_final,\n",
    "    k_bm25=cfg.k_bm25,\n",
    "    k_vec=cfg.k_vec,\n",
    "    rrf_k=cfg.rrf_k,\n",
    "    rewrite_n=cfg.rewrite_n,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e28218b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs: List[Document]) -> str:\n",
    "    lines = []\n",
    "    for d in docs:\n",
    "        page = d.metadata.get(\"page\", None)\n",
    "        if page is None:\n",
    "            lines.append(d.page_content)\n",
    "        else:\n",
    "            lines.append(f\"[p.{page+1}] {d.page_content}\")\n",
    "    return \"\\n\\n\".join(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "701f12e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "ë‹¤ìŒì€ ë¬¸ì„œì—ì„œ ê²€ìƒ‰ëœ ì •ë³´ì…ë‹ˆë‹¤:\n",
    "{context}\n",
    "\n",
    "ê·œì¹™:\n",
    "1) ê²€ìƒ‰ëœ ì •ë³´ì— ë“±ì¥í•˜ëŠ” í‘œí˜„, ëª…ì‚¬, êµ¬ë¬¸ì„ ìµœëŒ€í•œ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•´ ë‹µí•˜ì„¸ìš”.\n",
    "2) ì„¤ëª… ë¬¸ì¥ì€ ë§Œë“¤ì§€ ë§ê³ , **ì§§ì€ ëª…ì‚¬êµ¬ ë˜ëŠ” í•µì‹¬ í‚¤ì›Œë“œ**ë¡œ ë‹µí•˜ì„¸ìš”.\n",
    "3) ë¬¸ì„œì— ì§ì ‘ì ì¸ ë¬¸ì¥, ë¬˜ì‚¬, ë¹„ìœ ë¼ë„ ì¡´ì¬í•˜ë©´ ë°˜ë“œì‹œ ë‹µì„ ìƒì„±í•˜ì„¸ìš”.\n",
    "4) **ë¬¸ì„œ ì „ì²´ì— ì „í˜€ ë“±ì¥í•˜ì§€ ì•ŠëŠ” ê²½ìš°ì—ë§Œ** \"ì—†ëŠ” ì •ë³´\"ë¼ê³  ì¶œë ¥í•˜ì„¸ìš”.\n",
    "\n",
    "ì§ˆë¬¸: {question}\n",
    "\"\"\")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | parser\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0d4539a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langfuse\n",
    "langfuse_handler = CallbackHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0ae6d1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"ì´ì•¼ê¸°ì˜ ì œëª©ì€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "    \"ë¯¼ìˆ˜ê°€ ì²˜ìŒ ë“±ì¥í•˜ëŠ” ì¥ì†ŒëŠ” ì–´ë””ì¸ê°€ìš”?\",\n",
    "    \"ë¯¼ìˆ˜ê°€ ì²˜ìŒ ìš”êµ¬í•œ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "    \"ë¯¼ìˆ˜ê°€ ì‹«ì–´í•œë‹¤ê³  ë§í•œ ì•„í‚¤í…ì²˜ êµ¬ì¡°ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "    \"ë¯¼ìˆ˜ê°€ ì›í•˜ëŠ” AI ì¸í„´ì˜ ì¡°ê±´ ì¤‘ í•˜ë‚˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "    \"ë¯¼ìˆ˜ê°€ ì†í•œ ë¶€ì„œì˜ ì½”ë“œëª…ìœ¼ë¡œ ì¶”ì •ë˜ëŠ” ì´ë¦„ì€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "    \"ë¶€ì„œ B-612ëŠ” ì–´ë–¤ íŠ¹ì§•ì„ ê°€ì§„ ì¡°ì§ìœ¼ë¡œ ë¬˜ì‚¬ë˜ë‚˜ìš”?\",\n",
    "    \"ë¯¼ìˆ˜ëŠ” ë ˆê±°ì‹œ ì½”ë“œë¥¼ ì–´ë–»ê²Œ ì¸ì‹í•˜ê³  ìˆë‚˜ìš”?\",\n",
    "    \"ë¯¼ìˆ˜ê°€ ì¢‹ì•„í•œë‹¤ê³  ëª…í™•íˆ ì–¸ê¸‰í•œ ê·¼ë¬´ ë°©ì‹ì€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "    \"ë¯¼ìˆ˜ê°€ â€œë¡œë”© ë°” 100%ë¥¼ ë§ˆí”ë„¤ ë²ˆ ë´¤ë‹¤â€ê³  ë§í•œ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "    \"ë¯¼ìˆ˜ê°€ ì‚¬ë‘í•œë‹¤ê³  í‘œí˜„í•œ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "    \"í•µì‹¬ í”„ë¡œì íŠ¸ëŠ” ì–´ë–¤ íŠ¹ì„±ì„ ê°€ì§„ ê²ƒìœ¼ë¡œ ë¬˜ì‚¬ë˜ë‚˜ìš”?\",\n",
    "    \"ë¯¼ìˆ˜ê°€ í‡´ì‚¬ ì „ ë§ˆì§€ë§‰ìœ¼ë¡œ ì •ë¦¬í•œ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "    \"ì´ì•¼ê¸°ì—ì„œ â€˜ë³¸ë¶€ì¥â€™ ìºë¦­í„°ëŠ” ì–´ë–¤ ì¸ë¬¼ë¡œ í‘œí˜„ë˜ë‚˜ìš”?\",\n",
    "    \"â€˜ì¬ë¬´íŒ€ì¥â€™ì€ ìì‚°ì„ ì–´ë–»ê²Œ ë‹¤ë£¨ëŠ” ì¸ë¬¼ë¡œ ë¬˜ì‚¬ë˜ë‚˜ìš”?\",\n",
    "    \"ë¯¼ìˆ˜ê°€ ë§Œë‚œ â€˜ë‹¹ì§ ê·¼ë¬´ìâ€™ì˜ ì—­í• ì€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "    \"ë¯¼ìˆ˜ê°€ ë³¸ì‚¬ì—ì„œ ë§Œë‚œ í—¤ë“œí—Œí„°ëŠ” ì–´ë–¤ ì¡´ì¬ë¡œ ë¹„ìœ ë˜ë‚˜ìš”?\",\n",
    "    \"ë¯¼ìˆ˜ê°€ ì°¾ê³ ì í–ˆë˜ â€˜ì›íŒ€(One Team)â€™ì˜ ì˜ë¯¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "    \"ì´ ì‘í’ˆì—ì„œ ë¯¼ìˆ˜ì˜ ì •í™•í•œ ë‚˜ì´ëŠ” ì–¸ê¸‰ë˜ë‚˜ìš”?\",\n",
    "    \"ë¯¼ìˆ˜ê°€ ë‹¤ë‹ˆëŠ” íšŒì‚¬ì˜ ì‹¤ì œ íšŒì‚¬ëª…ì€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dd658d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q1: ì´ì•¼ê¸°ì˜ ì œëª©ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "Pred: ì˜¤í”¼ìŠ¤ ì”í˜¹ ë™í™”: ì‹ ì… ì‚¬ì› ë¯¼ìˆ˜ | Gold: ì˜¤í”¼ìŠ¤ ì”í˜¹ ë™í™”: ì‹ ì… ì‚¬ì› ë¯¼ìˆ˜\n",
      "\n",
      "Q2: ë¯¼ìˆ˜ê°€ ì²˜ìŒ ë“±ì¥í•˜ëŠ” ì¥ì†ŒëŠ” ì–´ë””ì¸ê°€ìš”?\n",
      "Pred: ë¶€ì„œ 325, 326, 327, 328, 329, 330í˜¸ ê·¼ì²˜ | Gold: ë³¸ì‚¬ ì§€í•˜ ì „ì‚°ì‹¤\n",
      "\n",
      "Q3: ë¯¼ìˆ˜ê°€ ì²˜ìŒ ìš”êµ¬í•œ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "Pred: \"ë¶€íƒì´ì•¼... AI ì¸í„´ í•˜ë‚˜ë§Œ ì§œì¤˜...\" | Gold: AI ì¸í„´ í•˜ë‚˜ë¥¼ ì½”ë”©í•´ ë‹¬ë¼ëŠ” ìš”ì²­\n",
      "\n",
      "Q4: ë¯¼ìˆ˜ê°€ ì‹«ì–´í•œë‹¤ê³  ë§í•œ ì•„í‚¤í…ì²˜ êµ¬ì¡°ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n",
      "Pred: ëª¨ë†€ë¦¬ì‹ êµ¬ì¡° ì•ˆì— ìˆëŠ” ìŠ¤íŒŒê²Œí‹° ì½”ë“œ | Gold: ëª¨ë†€ë¦¬ì‹(Monolithic) êµ¬ì¡°\n",
      "\n",
      "Q5: ë¯¼ìˆ˜ê°€ ì›í•˜ëŠ” AI ì¸í„´ì˜ ì¡°ê±´ ì¤‘ í•˜ë‚˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n",
      "Pred: \"ì˜¤ë˜ ìœ ì§€ë³´ìˆ˜í•  ìˆ˜ ìˆëŠ” AI\" | Gold: ì˜¤ë˜ ìœ ì§€ë³´ìˆ˜í•  ìˆ˜ ìˆëŠ” êµ¬ì¡°ì—¬ì•¼ í•¨\n",
      "\n",
      "Q6: ë¯¼ìˆ˜ê°€ ì†í•œ ë¶€ì„œì˜ ì½”ë“œëª…ìœ¼ë¡œ ì¶”ì •ë˜ëŠ” ì´ë¦„ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "Pred: ë¶€ì„œ B-612 | Gold: ë¶€ì„œ B-612\n",
      "\n",
      "Q7: ë¶€ì„œ B-612ëŠ” ì–´ë–¤ íŠ¹ì§•ì„ ê°€ì§„ ì¡°ì§ìœ¼ë¡œ ë¬˜ì‚¬ë˜ë‚˜ìš”?\n",
      "Pred: ë¶€ì„œ B-612ëŠ” ì•„ì£¼ ì‘ê³ , íšŒì˜ì‹¤ í•˜ë‚˜ë³´ë‹¤ í´ê¹Œ ë§ê¹Œ í•˜ë©°, 2020ë…„ ì™¸ë¶€ ì»¨ì„¤í„´íŠ¸ì— ì˜í•´ ë”± í•œ ë²ˆ ë³´ê³ ì„œì— ì¡íŒ ì ì´ ìˆë‹¤. ë¯¼ìˆ˜ê°€ ì…ì€ ìºì£¼ì–¼í•œ í›„ë“œí‹° ë•Œë¬¸ì— ì•„ë¬´ë„ ê·¸ì˜ ë§ì„ ë¯¿ì§€ ì•Šì•˜ê³ , ì„ì›ë“¤ì€ ìˆ«ìë¥¼ ì¢‹ì•„í•œë‹¤. ë¶€ì„œ ì½”ë“œê°€ ìˆìœ¼ë©°, ì„ì›ë“¤ì—ê²Œ ë‚©ë“ì„ ì£¼ê¸° ìœ„í•´ ì–¸ê¸‰ëœë‹¤. | Gold: íšŒì˜ì‹¤ í•˜ë‚˜ë³´ë‹¤ë„ ì‘ì€ ê·œëª¨ì˜ TF ì¡°ì§\n",
      "\n",
      "Q8: ë¯¼ìˆ˜ëŠ” ë ˆê±°ì‹œ ì½”ë“œë¥¼ ì–´ë–»ê²Œ ì¸ì‹í•˜ê³  ìˆë‚˜ìš”?\n",
      "Pred: ë ˆê±°ì‹œ ì½”ë“œëŠ” ì„±ë‹¹ë§Œí¼ì´ë‚˜ ê±°ëŒ€í•œ ê¸°ìˆ  ë¶€ì±„, ë„ˆë¬´ ëŠ¦ê²Œ ì†ì„ ì“°ë©´ ì˜ì˜ ì—†ì•¨ ìˆ˜ ì—†ë‹¤, ì˜ì¡´ì„±ì´ ì‹œìŠ¤í…œì— êµ¬ë©ì„ ëš«ëŠ”ë‹¤, í”„ë¡œì íŠ¸ëŠ” ì‚°ì‚°ì¡°ê°ì´ ë‚˜ë²„ë¦°ë‹¤, ë ˆê±°ì‹œ ì½”ë“œëŠ” ë˜¥ì´ ë˜ê¸° ì „ì—ëŠ” 'ìµœì‹  ê¸°ìˆ 'ë¡œ ì‹œì‘í•œë‹¤. | Gold: ì´ˆê¸°ì— ì •ë¦¬í•˜ì§€ ì•Šìœ¼ë©´ ì‹œìŠ¤í…œ ì „ì²´ë¥¼ ë§ê°€ëœ¨ë¦¬ëŠ” ìœ„í—˜ ìš”ì†Œ\n",
      "\n",
      "Q9: ë¯¼ìˆ˜ê°€ ì¢‹ì•„í•œë‹¤ê³  ëª…í™•íˆ ì–¸ê¸‰í•œ ê·¼ë¬´ ë°©ì‹ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "Pred: ì¹¼í‡´ | Gold: ì¹¼í‡´\n",
      "\n",
      "Q10: ë¯¼ìˆ˜ê°€ â€œë¡œë”© ë°” 100%ë¥¼ ë§ˆí”ë„¤ ë²ˆ ë´¤ë‹¤â€ê³  ë§í•œ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n",
      "Pred: ëª¹ì‹œ ë²ˆì•„ì›ƒì´ ì˜¬ ë•Œ. | Gold: ê·¹ì‹¬í•œ ë²ˆì•„ì›ƒ ìƒíƒœë¥¼ ë¹„ìœ ì ìœ¼ë¡œ í‘œí˜„í•œ ê²ƒ\n",
      "\n",
      "Q11: ë¯¼ìˆ˜ê°€ ì‚¬ë‘í•œë‹¤ê³  í‘œí˜„í•œ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "Pred: í”„ë¡œì íŠ¸ | Gold: í•µì‹¬ í”„ë¡œì íŠ¸\n",
      "\n",
      "Q12: í•µì‹¬ í”„ë¡œì íŠ¸ëŠ” ì–´ë–¤ íŠ¹ì„±ì„ ê°€ì§„ ê²ƒìœ¼ë¡œ ë¬˜ì‚¬ë˜ë‚˜ìš”?\n",
      "Pred: - ì¼ì‹œì \n",
      "- ë°©í™”ë²½ ë„¤ ê°œ\n",
      "- ë ˆê±°ì‹œ ì½”ë“œ\n",
      "- ê¸°ëŠ¥ ì¶”ê°€ë‚˜ UI ê°œì„ \n",
      "- ë¬´ì‹œë¬´ì‹œí•œ ì”¨ì•—\n",
      "- í”„ë¡œì íŠ¸ ì „ì²´ë¥¼ ë®ì–´ ë²„ë¦¼\n",
      "- ì˜ì¡´ì„±ì´ ì‹œìŠ¤í…œì— êµ¬ë©ì„ ëš«ìŒ\n",
      "- ì‚°ì‚°ì¡°ê°ì´ ë‚˜ë²„ë¦¼ (ë¹Œë“œ ì‹¤íŒ¨) | Gold: ê¸°ëŠ¥ì´ ë‹¨ìˆœí•˜ì§€ë§Œ ë¯¼ìˆ˜ì—ê²Œ ì˜ë¯¸ ìˆëŠ” í”„ë¡œì íŠ¸\n",
      "\n",
      "Q13: ë¯¼ìˆ˜ê°€ í‡´ì‚¬ ì „ ë§ˆì§€ë§‰ìœ¼ë¡œ ì •ë¦¬í•œ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "Pred: ë ˆê±°ì‹œ ì½”ë“œì˜ ë§ˆì§€ë§‰ ì£¼ì„ | Gold: ì‹¤í–‰ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ë“¤ê³¼ ë ˆê±°ì‹œ ì½”ë“œ ì£¼ì„\n",
      "\n",
      "Q14: ì´ì•¼ê¸°ì—ì„œ â€˜ë³¸ë¶€ì¥â€™ ìºë¦­í„°ëŠ” ì–´ë–¤ ì¸ë¬¼ë¡œ í‘œí˜„ë˜ë‚˜ìš”?\n",
      "Pred: - ê¶Œìœ„ ìˆëŠ” ë…ì¬ì\n",
      "- ë°˜ëŒ€ ì˜ê²¬ì„ ìš©ë‚©í•˜ì§€ ì•ŠìŒ\n",
      "- ì„ ëŸ‰í•œ ì§€ì‹œ\n",
      "- ëª¨ë“  ê²ƒì„ ê´€ë¦¬\n",
      "- ì§ì›ë“¤ì—ê²Œ ì¦‰ê° ë³µì¢… ìš”êµ¬\n",
      "- ê·¼íƒœ ë¶ˆëŸ‰ì„ ìš©ë‚©í•˜ì§€ ì•ŠìŒ\n",
      "- ìœ„ì—„ ìˆì–´ ë³´ì„\n",
      "- íŠ¹ì„ ëŒ€ì‚¬ë¡œ ì„ëª…í•˜ê² ë‹¤ê³  í•¨ | Gold: ê¶Œìœ„ì™€ ì§€ì‹œë¥¼ ì¤‘ì‹œí•˜ëŠ” ë‚™í•˜ì‚°í˜• ê´€ë¦¬ì\n",
      "\n",
      "Q15: â€˜ì¬ë¬´íŒ€ì¥â€™ì€ ìì‚°ì„ ì–´ë–»ê²Œ ë‹¤ë£¨ëŠ” ì¸ë¬¼ë¡œ ë¬˜ì‚¬ë˜ë‚˜ìš”?\n",
      "Pred: \"ê´€ë¦¬í•˜ì§€. ì„¸ê³  ë˜ ì„¸ì§€. ì–´ë ¤ìš´ ì¼ì´ì•¼. í•˜ì§€ë§Œ ë‚˜ëŠ” ì§„ì§€í•œ ì‚¬ëŒì´ë‹ˆê¹Œ.\" \"ìì‚°ì„ ì†Œìœ í•œ ë‹¤êµ¬ìš”?\" \"ê·¸ë˜.\" \"í•˜ì§€ë§Œ íŒ€ì¥ë‹˜ì€ ìì‚°ì„ ì“¸ ìˆ˜ ì—†ì–ì•„ìš”.\" \"ëª» ì“°ì§€. í•˜ì§€ë§Œ ì€í–‰ì— ì˜ˆì¹˜í•  ìˆ˜ëŠ” ìˆì–´.\" \"ì‘ì€ ì¢…ì´ ì¡°ê°(í†µì¥)ì— ë‚´ ìì‚°ì˜ ì•¡ìˆ˜ë¥¼ ì ì–´ì„œ ê¸ˆê³ ì— ë„£ê³  ì ê·¼ë‹¤ëŠ” ëœ»ì´ì•¼.\" \"ê·¸ê±¸ë¡œ ì¶©ë¶„í•´.\" | Gold: ìì‚°ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì†Œìœ ì™€ ê´€ë¦¬ë§Œ í•˜ëŠ” ì¸ë¬¼\n",
      "\n",
      "Q16: ë¯¼ìˆ˜ê°€ ë§Œë‚œ â€˜ë‹¹ì§ ê·¼ë¬´ìâ€™ì˜ ì—­í• ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "Pred: ì„œë²„ ëª¨ë‹ˆí„°ë§, ì„œë¹„ìŠ¤ í•˜ë‚˜ë‚˜ íŠ¸ë˜í”½ í•œ ì¤„ê¸°ë¥¼ ë” ì‚´ë ¤ë‚´ëŠ” ê²ƒ. | Gold: ì„œë²„ ëª¨ë‹ˆí„°ë§ê³¼ ë¡œê·¸ í™•ì¸ì„ ë°˜ë³µí•˜ëŠ” ì—­í• \n",
      "\n",
      "Q17: ë¯¼ìˆ˜ê°€ ë³¸ì‚¬ì—ì„œ ë§Œë‚œ í—¤ë“œí—Œí„°ëŠ” ì–´ë–¤ ì¡´ì¬ë¡œ ë¹„ìœ ë˜ë‚˜ìš”?\n",
      "Pred: **'í—¤ë“œí—Œí„°(ë±€)'** | Gold: ë±€\n",
      "\n",
      "Q18: ë¯¼ìˆ˜ê°€ ì°¾ê³ ì í–ˆë˜ â€˜ì›íŒ€(One Team)â€™ì˜ ì˜ë¯¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n",
      "Pred: 'ê´€ê³„ë¥¼ ë§ºëŠ”ë‹¤(Team Building)'ëŠ” ëœ». | Gold: ë‹¨ìˆœí•œ ì¡°ì§ì´ ì•„ë‹ˆë¼ ê´€ê³„ë¥¼ ë§ºì€ ë™ë£Œ ê´€ê³„\n",
      "\n",
      "Q19: ì´ ì‘í’ˆì—ì„œ ë¯¼ìˆ˜ì˜ ì •í™•í•œ ë‚˜ì´ëŠ” ì–¸ê¸‰ë˜ë‚˜ìš”?\n",
      "Pred: ì—†ëŠ” ì •ë³´ | Gold: ì—†ëŠ” ì •ë³´\n",
      "\n",
      "Q20: ë¯¼ìˆ˜ê°€ ë‹¤ë‹ˆëŠ” íšŒì‚¬ì˜ ì‹¤ì œ íšŒì‚¬ëª…ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "Pred: ì—†ëŠ” ì •ë³´ | Gold: ì—†ëŠ” ì •ë³´\n",
      "\n",
      "Grading:\n",
      "1ë²ˆ: 1ì  (ì •í™•íˆ ì¼ì¹˜)\n",
      "2ë²ˆ: 0ì  (ì „í˜€ ë‹¤ë¥¸ ì¥ì†Œ)\n",
      "3ë²ˆ: 0.5ì  (ìš”ì²­ì˜ ë‚´ìš©ì€ ë§ì§€ë§Œ í‘œí˜„ì´ ë‹¤ë¦„)\n",
      "4ë²ˆ: 0.5ì  (êµ¬ì¡°ì˜ ì´ë¦„ì€ ë§ì§€ë§Œ í˜•ì‹ì´ ë‹¤ë¦„)\n",
      "5ë²ˆ: 0.5ì  (ì˜ë¯¸ëŠ” ë§ì§€ë§Œ í‘œí˜„ì´ ë‹¤ë¦„)\n",
      "6ë²ˆ: 1ì  (ì •í™•íˆ ì¼ì¹˜)\n",
      "7ë²ˆ: 0ì  (íŠ¹ì§•ì´ ì „í˜€ ë‹¤ë¦„)\n",
      "8ë²ˆ: 0.5ì  (ìœ„í—˜ ìš”ì†Œì˜ ì˜ë¯¸ëŠ” ë§ì§€ë§Œ í‘œí˜„ì´ ë‹¤ë¦„)\n",
      "9ë²ˆ: 1ì  (ì •í™•íˆ ì¼ì¹˜)\n",
      "10ë²ˆ: 0.5ì  (ì˜ë¯¸ëŠ” ë§ì§€ë§Œ í‘œí˜„ì´ ë‹¤ë¦„)\n",
      "11ë²ˆ: 0.5ì  (í•µì‹¬ í”„ë¡œì íŠ¸ë¼ëŠ” êµ¬ì²´ì ì¸ í‘œí˜„ì´ ëˆ„ë½ë¨)\n",
      "12ë²ˆ: 0.5ì  (íŠ¹ì„±ì˜ ì¼ë¶€ëŠ” ë§ì§€ë§Œ êµ¬ì²´ì„±ì´ ë¶€ì¡±í•¨)\n",
      "13ë²ˆ: 0.5ì  (ì£¼ì„ì˜ ë‚´ìš©ì€ ë§ì§€ë§Œ êµ¬ì²´ì ì¸ ë‚´ìš©ì´ ëˆ„ë½ë¨)\n",
      "14ë²ˆ: 0.5ì  (ì¸ë¬¼ì˜ ì„±ê²©ì€ ë§ì§€ë§Œ í‘œí˜„ì´ ë‹¤ë¦„)\n",
      "15ë²ˆ: 1ì  (ì •í™•íˆ ì¼ì¹˜)\n",
      "16ë²ˆ: 0.5ì  (ì—­í• ì˜ ì¼ë¶€ëŠ” ë§ì§€ë§Œ í‘œí˜„ì´ ë‹¤ë¦„)\n",
      "17ë²ˆ: 1ì  (ì •í™•íˆ ì¼ì¹˜)\n",
      "18ë²ˆ: 0.5ì  (ì˜ë¯¸ëŠ” ë§ì§€ë§Œ í‘œí˜„ì´ ë‹¤ë¦„)\n",
      "19ë²ˆ: 1ì  (ì •í™•íˆ ì¼ì¹˜)\n",
      "20ë²ˆ: 1ì  (ì •í™•íˆ ì¼ì¹˜)\n",
      "Total: 12.5 / 20\n"
     ]
    }
   ],
   "source": [
    "predicted_answers = []\n",
    "for i, q in enumerate(questions, start=1):\n",
    "    ans = chain.invoke(q,     config={\n",
    "        \"callbacks\": [langfuse_handler],\n",
    "        \"metadata\": {\n",
    "            \"run_name\": \"rag_eval\",\n",
    "            \"k_final\": cfg.k_final,\n",
    "            \"rewrite_n\": cfg.rewrite_n,\n",
    "        },\n",
    "    },)\n",
    "    predicted_answers.append(ans)\n",
    "    print(f\"\\nQ{i}: {q}\")\n",
    "    print(f\"Pred: {ans} | Gold: {answer_key[i-1]}\")\n",
    "\n",
    "print(\"\\nGrading:\")\n",
    "grading_result = grade_predictions(questions, predicted_answers)\n",
    "print(grading_result)\n",
    "\n",
    "total_score, per_item_scores = extract_scores_test(grading_result)\n",
    "print(f\"Total: {total_score} / {len(per_item_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "48eb7f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q1: ì´ì•¼ê¸°ì˜ ì œëª©ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "Pred: ì˜¤í”¼ìŠ¤ ì”í˜¹ ë™í™”: ì‹ ì… ì‚¬ì› ë¯¼ìˆ˜ | Gold: ì˜¤í”¼ìŠ¤ ì”í˜¹ ë™í™”: ì‹ ì… ì‚¬ì› ë¯¼ìˆ˜\n",
      "\n",
      "Q2: ë¯¼ìˆ˜ê°€ ì²˜ìŒ ë“±ì¥í•˜ëŠ” ì¥ì†ŒëŠ” ì–´ë””ì¸ê°€ìš”?\n",
      "Pred: ë¶€ì„œ 325, 326, 327, 328, 329, 330í˜¸ ê·¼ì²˜ | Gold: ë³¸ì‚¬ ì§€í•˜ ì „ì‚°ì‹¤\n",
      "\n",
      "Q3: ë¯¼ìˆ˜ê°€ ì²˜ìŒ ìš”êµ¬í•œ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "Pred: \"ë¶€íƒì´ì•¼... AI ì¸í„´ í•˜ë‚˜ë§Œ ì§œì¤˜...\" | Gold: AI ì¸í„´ í•˜ë‚˜ë¥¼ ì½”ë”©í•´ ë‹¬ë¼ëŠ” ìš”ì²­\n",
      "\n",
      "Q4: ë¯¼ìˆ˜ê°€ ì‹«ì–´í•œë‹¤ê³  ë§í•œ ì•„í‚¤í…ì²˜ êµ¬ì¡°ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n",
      "Pred: ëª¨ë†€ë¦¬ì‹ êµ¬ì¡° ì•ˆì— ìˆëŠ” ìŠ¤íŒŒê²Œí‹° ì½”ë“œ | Gold: ëª¨ë†€ë¦¬ì‹(Monolithic) êµ¬ì¡°\n",
      "\n",
      "Q5: ë¯¼ìˆ˜ê°€ ì›í•˜ëŠ” AI ì¸í„´ì˜ ì¡°ê±´ ì¤‘ í•˜ë‚˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n",
      "Pred: \"ì˜¤ë˜ ìœ ì§€ë³´ìˆ˜í•  ìˆ˜ ìˆëŠ” AI\" | Gold: ì˜¤ë˜ ìœ ì§€ë³´ìˆ˜í•  ìˆ˜ ìˆëŠ” êµ¬ì¡°ì—¬ì•¼ í•¨\n",
      "\n",
      "Q6: ë¯¼ìˆ˜ê°€ ì†í•œ ë¶€ì„œì˜ ì½”ë“œëª…ìœ¼ë¡œ ì¶”ì •ë˜ëŠ” ì´ë¦„ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "Pred: ë¶€ì„œ B-612 | Gold: ë¶€ì„œ B-612\n",
      "\n",
      "Q7: ë¶€ì„œ B-612ëŠ” ì–´ë–¤ íŠ¹ì§•ì„ ê°€ì§„ ì¡°ì§ìœ¼ë¡œ ë¬˜ì‚¬ë˜ë‚˜ìš”?\n",
      "Pred: ë¶€ì„œ B-612ëŠ” ì•„ì£¼ ì‘ê³ , íšŒì˜ì‹¤ í•˜ë‚˜ë³´ë‹¤ í´ê¹Œ ë§ê¹Œ í•˜ë©°, 2020ë…„ ì™¸ë¶€ ì»¨ì„¤í„´íŠ¸ì— ì˜í•´ ë”± í•œ ë²ˆ ë³´ê³ ì„œì— ì¡íŒ ì ì´ ìˆë‹¤. ë¯¼ìˆ˜ê°€ ì…ì€ ìºì£¼ì–¼í•œ í›„ë“œí‹° ë•Œë¬¸ì— ì•„ë¬´ë„ ê·¸ì˜ ë§ì„ ë¯¿ì§€ ì•Šì•˜ê³ , ì„ì›ë“¤ì€ ìˆ«ìë¥¼ ì¢‹ì•„í•œë‹¤. ë¶€ì„œ ì½”ë“œê°€ ìˆìœ¼ë©°, ì„ì›ë“¤ì—ê²Œ ë‚©ë“ì„ ì£¼ê¸° ìœ„í•´ ë¶€ì„œ ì´ë¦„ ëŒ€ì‹  ì½”ë“œë¡œ ì–¸ê¸‰ëœë‹¤. | Gold: íšŒì˜ì‹¤ í•˜ë‚˜ë³´ë‹¤ë„ ì‘ì€ ê·œëª¨ì˜ TF ì¡°ì§\n",
      "\n",
      "Q8: ë¯¼ìˆ˜ëŠ” ë ˆê±°ì‹œ ì½”ë“œë¥¼ ì–´ë–»ê²Œ ì¸ì‹í•˜ê³  ìˆë‚˜ìš”?\n",
      "Pred: ë ˆê±°ì‹œ ì½”ë“œëŠ” ì„±ë‹¹ë§Œí¼ì´ë‚˜ ê±°ëŒ€í•œ ê¸°ìˆ  ë¶€ì±„, ë„ˆë¬´ ëŠ¦ê²Œ ì†ì„ ì“°ë©´ ì˜ì˜ ì—†ì•¨ ìˆ˜ ì—†ë‹¤, ì˜ì¡´ì„±ì´ ì‹œìŠ¤í…œì— êµ¬ë©ì„ ëš«ëŠ”ë‹¤, ë ˆê±°ì‹œ ì½”ë“œë„ ë˜¥ì´ ë˜ê¸° ì „ì—ëŠ” 'ìµœì‹  ê¸°ìˆ 'ë¡œ ì‹œì‘í•œë‹¤, ë ˆê±°ì‹œ ì½”ë“œëŠ” ì§¤ ë•ŒëŠ” í•µì‹¬ ê¸°ëŠ¥ê³¼ ë¬´ì²™ ë‹®ì•˜ë‹¤. | Gold: ì´ˆê¸°ì— ì •ë¦¬í•˜ì§€ ì•Šìœ¼ë©´ ì‹œìŠ¤í…œ ì „ì²´ë¥¼ ë§ê°€ëœ¨ë¦¬ëŠ” ìœ„í—˜ ìš”ì†Œ\n",
      "\n",
      "Q9: ë¯¼ìˆ˜ê°€ ì¢‹ì•„í•œë‹¤ê³  ëª…í™•íˆ ì–¸ê¸‰í•œ ê·¼ë¬´ ë°©ì‹ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "Pred: ì¹¼í‡´ | Gold: ì¹¼í‡´\n",
      "\n",
      "Q10: ë¯¼ìˆ˜ê°€ â€œë¡œë”© ë°” 100%ë¥¼ ë§ˆí”ë„¤ ë²ˆ ë´¤ë‹¤â€ê³  ë§í•œ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n",
      "Pred: ëª¹ì‹œ ë²ˆì•„ì›ƒì´ ì˜¬ ë•Œì—ëŠ” ìœˆë„ìš° ì¢…ë£Œ í™”ë©´ì´ ë³´ê³  ì‹¶ì–´ì§€ëŠ” ê±°. | Gold: ê·¹ì‹¬í•œ ë²ˆì•„ì›ƒ ìƒíƒœë¥¼ ë¹„ìœ ì ìœ¼ë¡œ í‘œí˜„í•œ ê²ƒ\n",
      "\n",
      "Q11: ë¯¼ìˆ˜ê°€ ì‚¬ë‘í•œë‹¤ê³  í‘œí˜„í•œ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "Pred: í”„ë¡œì íŠ¸ | Gold: í•µì‹¬ í”„ë¡œì íŠ¸\n",
      "\n",
      "Q12: í•µì‹¬ í”„ë¡œì íŠ¸ëŠ” ì–´ë–¤ íŠ¹ì„±ì„ ê°€ì§„ ê²ƒìœ¼ë¡œ ë¬˜ì‚¬ë˜ë‚˜ìš”?\n",
      "Pred: - ìì¡´ì‹¬ì´ ê°•í•œ 'í•µì‹¬ í”„ë¡œì íŠ¸'\n",
      "- ì¼ì‹œì ì´ì§€ ì•ŠìŒ\n",
      "- ë°©í™”ë²½ ë„¤ ê°œ\n",
      "- ë ˆê±°ì‹œ ì½”ë“œì˜ ì”¨ì•—\n",
      "- í”„ë¡œì íŠ¸ ì „ì²´ë¥¼ ë®ì–´ ë²„ë¦¼\n",
      "- ì˜ì¡´ì„±ì´ ì‹œìŠ¤í…œì— êµ¬ë©ì„ ëš«ìŒ\n",
      "- ì‚°ì‚°ì¡°ê°ì´ ë‚˜ë²„ë¦¼ (ë¹Œë“œ ì‹¤íŒ¨) | Gold: ê¸°ëŠ¥ì´ ë‹¨ìˆœí•˜ì§€ë§Œ ë¯¼ìˆ˜ì—ê²Œ ì˜ë¯¸ ìˆëŠ” í”„ë¡œì íŠ¸\n",
      "\n",
      "Q13: ë¯¼ìˆ˜ê°€ í‡´ì‚¬ ì „ ë§ˆì§€ë§‰ìœ¼ë¡œ ì •ë¦¬í•œ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "Pred: ë ˆê±°ì‹œ ì½”ë“œì˜ ë§ˆì§€ë§‰ ì£¼ì„ | Gold: ì‹¤í–‰ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ë“¤ê³¼ ë ˆê±°ì‹œ ì½”ë“œ ì£¼ì„\n",
      "\n",
      "Q14: ì´ì•¼ê¸°ì—ì„œ â€˜ë³¸ë¶€ì¥â€™ ìºë¦­í„°ëŠ” ì–´ë–¤ ì¸ë¬¼ë¡œ í‘œí˜„ë˜ë‚˜ìš”?\n",
      "Pred: - ê¶Œìœ„ ìˆëŠ” ë…ì¬ì\n",
      "- ìì‹ ì˜ ê¶Œìœ„ ì¡´ì¤‘ ì›í•¨\n",
      "- ì´ì¹˜ì— ë§ëŠ” ì§€ì‹œë§Œ ë‚´ë¦¼\n",
      "- ì§ì›ë“¤ì—ê²Œ ë³µì¢… ìš”êµ¬\n",
      "- ê·¼íƒœ ë¶ˆëŸ‰ ìš©ë‚©í•˜ì§€ ì•ŠìŒ\n",
      "- ì—…ê³„ì˜ ì œì™•\n",
      "- ìë‘ìŠ¤ëŸ¬ìš´ ì§€ì‹œ\n",
      "- íŠ¹ì„ ëŒ€ì‚¬ë¡œ ì„ëª…í•˜ê² ë‹¤ê³  í•¨ | Gold: ê¶Œìœ„ì™€ ì§€ì‹œë¥¼ ì¤‘ì‹œí•˜ëŠ” ë‚™í•˜ì‚°í˜• ê´€ë¦¬ì\n",
      "\n",
      "Q15: â€˜ì¬ë¬´íŒ€ì¥â€™ì€ ìì‚°ì„ ì–´ë–»ê²Œ ë‹¤ë£¨ëŠ” ì¸ë¬¼ë¡œ ë¬˜ì‚¬ë˜ë‚˜ìš”?\n",
      "Pred: \"ê´€ë¦¬í•˜ì§€. ì„¸ê³  ë˜ ì„¸ì§€. ì–´ë ¤ìš´ ì¼ì´ì•¼. í•˜ì§€ë§Œ ë‚˜ëŠ” ì§„ì§€í•œ ì‚¬ëŒì´ë‹ˆê¹Œ.\" \"ìì‚°ì„ ì†Œìœ í•œ ë‹¤êµ¬ìš”?\" \"ê·¸ë˜.\" \"í•˜ì§€ë§Œ íŒ€ì¥ë‹˜ì€ ìì‚°ì„ ì“¸ ìˆ˜ ì—†ì–ì•„ìš”.\" \"ëª» ì“°ì§€. í•˜ì§€ë§Œ ì€í–‰ì— ì˜ˆì¹˜í•  ìˆ˜ëŠ” ìˆì–´.\" \"ì‘ì€ ì¢…ì´ ì¡°ê°(í†µì¥)ì— ë‚´ ìì‚°ì˜ ì•¡ìˆ˜ë¥¼ ì ì–´ì„œ ê¸ˆê³ ì— ë„£ê³  ì ê·¼ë‹¤ëŠ” ëœ»ì´ì•¼.\" \"ê·¸ê±¸ë¡œ ì¶©ë¶„í•´.\" | Gold: ìì‚°ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì†Œìœ ì™€ ê´€ë¦¬ë§Œ í•˜ëŠ” ì¸ë¬¼\n",
      "\n",
      "Q16: ë¯¼ìˆ˜ê°€ ë§Œë‚œ â€˜ë‹¹ì§ ê·¼ë¬´ìâ€™ì˜ ì—­í• ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "Pred: ì„œë²„ ëª¨ë‹ˆí„°ë§, ì„œë¹„ìŠ¤ í•˜ë‚˜ë‚˜ íŠ¸ë˜í”½ í•œ ì¤„ê¸°ë¥¼ ë” ì‚´ë ¤ë‚´ëŠ” ê²ƒ. | Gold: ì„œë²„ ëª¨ë‹ˆí„°ë§ê³¼ ë¡œê·¸ í™•ì¸ì„ ë°˜ë³µí•˜ëŠ” ì—­í• \n",
      "\n",
      "Q17: ë¯¼ìˆ˜ê°€ ë³¸ì‚¬ì—ì„œ ë§Œë‚œ í—¤ë“œí—Œí„°ëŠ” ì–´ë–¤ ì¡´ì¬ë¡œ ë¹„ìœ ë˜ë‚˜ìš”?\n",
      "Pred: **'í—¤ë“œí—Œí„°(ë±€)'** | Gold: ë±€\n",
      "\n",
      "Q18: ë¯¼ìˆ˜ê°€ ì°¾ê³ ì í–ˆë˜ â€˜ì›íŒ€(One Team)â€™ì˜ ì˜ë¯¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n",
      "Pred: 'ê´€ê³„ë¥¼ ë§ºëŠ”ë‹¤(Team Building)'ëŠ” ëœ». | Gold: ë‹¨ìˆœí•œ ì¡°ì§ì´ ì•„ë‹ˆë¼ ê´€ê³„ë¥¼ ë§ºì€ ë™ë£Œ ê´€ê³„\n",
      "\n",
      "Q19: ì´ ì‘í’ˆì—ì„œ ë¯¼ìˆ˜ì˜ ì •í™•í•œ ë‚˜ì´ëŠ” ì–¸ê¸‰ë˜ë‚˜ìš”?\n",
      "Pred: ì—†ëŠ” ì •ë³´ | Gold: ì—†ëŠ” ì •ë³´\n",
      "\n",
      "Q20: ë¯¼ìˆ˜ê°€ ë‹¤ë‹ˆëŠ” íšŒì‚¬ì˜ ì‹¤ì œ íšŒì‚¬ëª…ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "Pred: ì—†ëŠ” ì •ë³´ | Gold: ì—†ëŠ” ì •ë³´\n",
      "\n",
      "Grading:\n",
      "1ë²ˆ: 1ì  (ì •í™•íˆ ì¼ì¹˜í•¨)\n",
      "2ë²ˆ: 0ì  (ì „í˜€ ë‹¤ë¥¸ ì¥ì†Œë¥¼ ì–¸ê¸‰í•¨)\n",
      "3ë²ˆ: 0.5ì  (ìš”ì²­ì˜ ë‚´ìš©ì€ ë§ì§€ë§Œ í‘œí˜„ì´ ë‹¤ë¦„)\n",
      "4ë²ˆ: 0.5ì  (êµ¬ì¡°ì˜ ì´ë¦„ì€ ë§ì§€ë§Œ í˜•ì‹ì´ ë‹¤ë¦„)\n",
      "5ë²ˆ: 0.5ì  (ì˜ë¯¸ëŠ” ë§ì§€ë§Œ í‘œí˜„ì´ ë‹¤ë¦„)\n",
      "6ë²ˆ: 1ì  (ì •í™•íˆ ì¼ì¹˜í•¨)\n",
      "7ë²ˆ: 0ì  (íŠ¹ì§•ì´ ì „í˜€ ë‹¤ë¦„)\n",
      "8ë²ˆ: 0.5ì  (ìœ„í—˜ ìš”ì†Œì— ëŒ€í•œ ì„¤ëª…ì€ ë§ì§€ë§Œ í‘œí˜„ì´ ë‹¤ë¦„)\n",
      "9ë²ˆ: 1ì  (ì •í™•íˆ ì¼ì¹˜í•¨)\n",
      "10ë²ˆ: 0.5ì  (ë¹„ìœ ì˜ ì˜ë¯¸ëŠ” ë§ì§€ë§Œ í‘œí˜„ì´ ë‹¤ë¦„)\n",
      "11ë²ˆ: 0.5ì  (ì‚¬ë‘í•˜ëŠ” ëŒ€ìƒì„ ì–¸ê¸‰í–ˆì§€ë§Œ êµ¬ì²´ì„±ì´ ë¶€ì¡±í•¨)\n",
      "12ë²ˆ: 0ì  (íŠ¹ì„±ì´ ì „í˜€ ë‹¤ë¦„)\n",
      "13ë²ˆ: 0.5ì  (ì •ë¦¬í•œ ë‚´ìš©ì€ ë§ì§€ë§Œ êµ¬ì²´ì„±ì´ ë¶€ì¡±í•¨)\n",
      "14ë²ˆ: 0.5ì  (ì¸ë¬¼ì˜ ì„±ê²©ì€ ë§ì§€ë§Œ í‘œí˜„ì´ ë‹¤ë¦„)\n",
      "15ë²ˆ: 1ì  (ì •í™•íˆ ì¼ì¹˜í•¨)\n",
      "16ë²ˆ: 0.5ì  (ì—­í• ì˜ ì¼ë¶€ëŠ” ë§ì§€ë§Œ í‘œí˜„ì´ ë‹¤ë¦„)\n",
      "17ë²ˆ: 1ì  (ì •í™•íˆ ì¼ì¹˜í•¨)\n",
      "18ë²ˆ: 0.5ì  (ì˜ë¯¸ëŠ” ë§ì§€ë§Œ í‘œí˜„ì´ ë‹¤ë¦„)\n",
      "19ë²ˆ: 1ì  (ì •í™•íˆ ì¼ì¹˜í•¨)\n",
      "20ë²ˆ: 1ì  (ì •í™•íˆ ì¼ì¹˜í•¨)\n",
      "âœ… ë¦¬ë”ë³´ë“œ ì œì¶œ ì™„ë£Œ | ì•ˆí˜¸ì„± | 12.00000\n",
      "Total: 12.0 / 20\n"
     ]
    }
   ],
   "source": [
    "predicted_answers = []\n",
    "for i, q in enumerate(questions, start=1):\n",
    "    ans = chain.invoke(q,     config={\n",
    "        \"callbacks\": [langfuse_handler],\n",
    "        \"metadata\": {\n",
    "            \"run_name\": \"rag_eval\",\n",
    "            \"k_final\": cfg.k_final,\n",
    "            \"rewrite_n\": cfg.rewrite_n,\n",
    "        },\n",
    "    },)\n",
    "    predicted_answers.append(ans)\n",
    "    print(f\"\\nQ{i}: {q}\")\n",
    "    print(f\"Pred: {ans} | Gold: {answer_key[i-1]}\")\n",
    "\n",
    "print(\"\\nGrading:\")\n",
    "grading_result = grade_predictions(questions, predicted_answers)\n",
    "print(grading_result)\n",
    "\n",
    "total_score, per_item_scores = extract_scores(grading_result)\n",
    "print(f\"Total: {total_score} / {len(per_item_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52918981",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
