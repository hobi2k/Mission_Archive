{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bcZc42Acap0"
      },
      "source": [
        "# RAG 시스템 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5JWyAnQdj2b"
      },
      "source": [
        "## 개요\n",
        "\n",
        "- 사용 데이터: 2024년 연말정산 신고 안내 문서\n",
        "\n",
        "- 설계\n",
        "| 태스크 | 기술 |\n",
        "|----------------|-----------------------------|\n",
        "| 데이터 전처리 | 데이터 로드, 전처리 |\n",
        "| 사용 LLM | yanolja/YanoljaNEXT-EEVE-Instruct-7B-v2-Previewe  |\n",
        "| 사용 임베딩 | dragonkue/BGE-m3-ko  |\n",
        "| 사용 DB | FAISS |\n",
        "| Cross-Encoder | BAAI/bge-reranker-v2-m3 |\n",
        "| 사용 웹검색 엔진 | DuckDuckGoSearch |\n",
        "| 사용 에이전트 프레임워크 | Langraph |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ho_-cURBi2An"
      },
      "source": [
        "# 1. 환경 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTHM-hOS4ICv",
        "outputId": "f21af4eb-b2f8-4054-fadd-f59fc682e49c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-huggingface\n",
            "  Downloading langchain_huggingface-1.2.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.33.4 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from langchain-huggingface) (0.36.0)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.0 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from langchain-huggingface) (1.2.7)\n",
            "Requirement already satisfied: tokenizers<1.0.0,>=0.19.1 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from langchain-huggingface) (0.21.0)\n",
            "Requirement already satisfied: filelock in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.20.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (6.0.3)\n",
            "Requirement already satisfied: requests in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2.32.5)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (1.2.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.6.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (2.12.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (9.1.2)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.25.0)\n",
            "Requirement already satisfied: anyio in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (4.12.0)\n",
            "Requirement already satisfied: certifi in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (1.0.9)\n",
            "Requirement already satisfied: idna in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2.6.2)\n",
            "Downloading langchain_huggingface-1.2.0-py3-none-any.whl (30 kB)\n",
            "Installing collected packages: langchain-huggingface\n",
            "Successfully installed langchain-huggingface-1.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQzECglo4ICw",
        "outputId": "a381436e-258c-400d-c08e-d75578f697ac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ddgs\n",
            "  Downloading ddgs-9.10.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from ddgs) (8.3.1)\n",
            "Collecting primp>=0.15.0 (from ddgs)\n",
            "  Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: lxml>=4.9.4 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from ddgs) (6.0.2)\n",
            "Requirement already satisfied: httpx>=0.28.1 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.28.1)\n",
            "Collecting fake-useragent>=2.2.0 (from ddgs)\n",
            "  Downloading fake_useragent-2.2.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: anyio in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.12.0)\n",
            "Requirement already satisfied: certifi in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.9)\n",
            "Requirement already satisfied: idna in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.16.0)\n",
            "Requirement already satisfied: brotli in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.2.0)\n",
            "Collecting h2<5,>=3 (from httpx[brotli,http2,socks]>=0.28.1->ddgs)\n",
            "  Downloading h2-4.3.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting socksio==1.* (from httpx[brotli,http2,socks]>=0.28.1->ddgs)\n",
            "  Downloading socksio-1.0.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting hyperframe<7,>=6.1 (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs)\n",
            "  Downloading hyperframe-6.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting hpack<5,>=4.1 (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs)\n",
            "  Downloading hpack-4.1.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages (from anyio->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.15.0)\n",
            "Downloading ddgs-9.10.0-py3-none-any.whl (40 kB)\n",
            "Downloading fake_useragent-2.2.0-py3-none-any.whl (161 kB)\n",
            "Downloading h2-4.3.0-py3-none-any.whl (61 kB)\n",
            "Downloading hpack-4.1.0-py3-none-any.whl (34 kB)\n",
            "Downloading hyperframe-6.1.0-py3-none-any.whl (13 kB)\n",
            "Downloading socksio-1.0.0-py3-none-any.whl (12 kB)\n",
            "Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: socksio, primp, hyperframe, hpack, fake-useragent, h2, ddgs\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7/7\u001b[0m [ddgs][32m3/7\u001b[0m [hpack]\n",
            "\u001b[1A\u001b[2KSuccessfully installed ddgs-9.10.0 fake-useragent-2.2.0 h2-4.3.0 hpack-4.1.0 hyperframe-6.1.0 primp-0.15.0 socksio-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U ddgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UONlBt_AbFnB",
        "outputId": "54958a1a-381e-40a9-b956-720366f1fdb6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ahnhs2k/pytorch-demo/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 데이터, 경로, 상태용\n",
        "import os\n",
        "import re\n",
        "import math\n",
        "import hashlib\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "from typing import List, Dict, Any, TypedDict, Tuple, Optional\n",
        "\n",
        "# 허깅페이스 트랜스포머\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "import torch\n",
        "\n",
        "# Cross-Encoder Reranker\n",
        "from sentence_transformers import CrossEncoder\n",
        "\n",
        "# 랭체인\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.llms import HuggingFacePipeline\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "from langchain_community.retrievers import BM25Retriever\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "\n",
        "# 랭그래프\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# langfuse 환경변수용\n",
        "from langfuse.langchain import CallbackHandler\n",
        "from dotenv import load_dotenv  # .env 파일에 정의된 환경 변수(API 키 등)를 현재 실행 환경에 로드\n",
        "load_dotenv()  # .env 파일의 내용을 읽어 os.environ에 반영"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8Gx0MqW8QXZi"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Config 클래스 정의\n",
        "\n",
        "- 상수 변수 정의\n",
        "- @dataclass 데코레이터 추가\n",
        "\"\"\"\n",
        "@dataclass\n",
        "class Config:\n",
        "    # 데이터 폴더 생성\n",
        "    root = Path(\".\")\n",
        "    raw_dir = root / \"data\"\n",
        "    data_dir = raw_dir / \"2024년_원천징수의무자를위한연말정산신간고안내.pdf\"\n",
        "    model_dir = root / \"models\"\n",
        "\n",
        "    # 청킹\n",
        "    chunk_size = 1100\n",
        "    chunk_overlap = 180\n",
        "\n",
        "    # Retrieval\n",
        "    dense_k: int = 30     # 임베딩 벡터에 쓰는 k\n",
        "    sparse_k: int = 30    # bm25에 쓰는 k\n",
        "    rrf_k: int = 60       # RRF에서 쓰는 k\n",
        "    rrf_pool: int = 60    # RRF 결과 중 rerank 대상으로 올릴 후보 수\n",
        "\n",
        "    # Rerank\n",
        "    rerank_top_n: int = 24  # Cross-Encoder에게 넘길 후보 수(너무 크면 느림)\n",
        "    final_k: int = 6        # 최종 컨텍스트에 포함할 top-k\n",
        "\n",
        "    # Web fallback gate\n",
        "    # Cross-Encoder 점수는 모델마다 스케일이 다를 수 있으므로 절대값 임계치 + 상대격차\n",
        "    rerank_min_score: float = 0.15   # top1이 이보다 낮으면 \"근거 부족\"으로 판단\n",
        "    rerank_min_margin: float = 0.03  # top1-top2가 너무 작으면 애매하다고 보고 fallback 고려\n",
        "\n",
        "    max_context_chars: int = 5000     # LLM 컨텍스트 최대 길이\n",
        "\n",
        "    # 생성용 파라미터\n",
        "    max_new_tokens: int = 512\n",
        "    temperature: float = 0.0\n",
        "\n",
        "    # 디바이스 설정\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # 후처리 함수 설정\n",
        "    def __post_init__(self):\n",
        "        self.raw_dir.mkdir(parents=True, exist_ok=True)\n",
        "        self.model_dir.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wf-eejLTbJAh"
      },
      "outputs": [],
      "source": [
        "# 변수 생성 및 폴더 생성\n",
        "cfg = Config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBpOiejj4ICw"
      },
      "source": [
        "# 2. 모델 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aY1hy1nU4ICx",
        "outputId": "432e018c-bd58-43a7-f2eb-1b9b96f0c068"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  2.22s/it]\n"
          ]
        }
      ],
      "source": [
        "# 모델명 변수\n",
        "model_id = \"yanolja/YanoljaNEXT-EEVE-Instruct-7B-v2-Preview\"\n",
        "\n",
        "# 모델 로컬 저장 경로 지정\n",
        "eeve_dir = cfg.model_dir / \"eeve\"\n",
        "\n",
        "# 토크나이저 및 모델 생성\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, cache_dir=eeve_dir)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    cache_dir=eeve_dir,\n",
        "    device_map=\"auto\",\n",
        "    # 4bit로 불러오기\n",
        "    load_in_4bit=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cC4zonpv4ICx",
        "outputId": "4649bdde-4540-4a28-d732-9393d964e85a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "# 랭체인용 파이프라인 생성\n",
        "text_gen_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=cfg.max_new_tokens,\n",
        "    do_sample=False,\n",
        "    temperature=None,\n",
        "    top_p=None,\n",
        "    top_k=None,\n",
        "    repetition_penalty=1.1,\n",
        "    return_full_text=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LjueRQWP4ICx"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_50508/11032916.py:2: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFacePipeline``.\n",
            "  llm = HuggingFacePipeline(pipeline=text_gen_pipeline)\n"
          ]
        }
      ],
      "source": [
        "# 랭체인에 사용할 LLM 래퍼\n",
        "llm = HuggingFacePipeline(pipeline=text_gen_pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "j2FDUTjG4ICx",
        "outputId": "299dc24c-b4d5-4592-e719-8d36bc679f48"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_50508/2916334341.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = HuggingFaceEmbeddings(\n"
          ]
        }
      ],
      "source": [
        "# 임베딩 모델 생성\n",
        "# normalize_embeddings로 코사인 유사도 안정화\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"dragonkue/BGE-m3-ko\",\n",
        "    encode_kwargs={\"normalize_embeddings\": True}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GKVpduU04ICx"
      },
      "outputs": [],
      "source": [
        "# 랭퓨즈 초기화\n",
        "langfuse_handler = CallbackHandler()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLNd5mG34ICx"
      },
      "source": [
        "# 3. PDF 로드 및 처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6KDR0u0d4ICx"
      },
      "outputs": [],
      "source": [
        "# PDF 로드\n",
        "loader = PyPDFLoader(str(cfg.data_dir))\n",
        "raw_docs = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "HVcDgGs54ICx"
      },
      "outputs": [],
      "source": [
        "# 데이터 청킹\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=cfg.chunk_size,\n",
        "    chunk_overlap=cfg.chunk_overlap,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \"•\", \"○\", \"①\", \"②\", \"③\", \".\", \" \", \"\"],\n",
        ")\n",
        "\n",
        "docs = splitter.split_documents(raw_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "iTfyFjVl4ICx"
      },
      "outputs": [],
      "source": [
        "# 각 문서 청크(Document)에 고유한 chunk_id를 부여\n",
        "# 목적\n",
        "# 1. RRF(Dense + Sparse 결과 병합) 시 동일 청크 식별\n",
        "# 2. Reranking, 중복 제거 시 추적\n",
        "# 3. 답변 근거 표시용\n",
        "\n",
        "for i, d in enumerate(docs):\n",
        "    # PDF loader가 자동으로 넣어주는 메타데이터 형태:\n",
        "    # d.metadata = {\"source\":, \"page\":}\n",
        "\n",
        "    # 문서 출처(source)를 문자열로 가져옴\n",
        "    src = str(d.metadata.get(\"source\", \"pdf\"))\n",
        "\n",
        "    # PDF 페이지 번호를 문자열로 가져옴\n",
        "    page = str(d.metadata.get(\"page\", \"NA\"))\n",
        "\n",
        "    # 고유 해시 생성\n",
        "    # - source + page + 청크 인덱스를 결합\n",
        "    # - 같은 PDF의 같은 페이지라도, 다른 청크면 다른 ID가 되도록 설계\n",
        "\n",
        "    # 1. 고유 문자열 생성\n",
        "    raw_key = src + \"|\" + page + \"|\" + str(i)\n",
        "\n",
        "    # 2. 문자열을 바이트로 변환 (hash 함수 입력용)\n",
        "    raw_bytes = raw_key.encode(\"utf-8\")\n",
        "\n",
        "    # 3. MD5 해시 계산: 32자리 16진수 문자열\n",
        "    # 4. 앞 10자리만 사용\n",
        "    h = hashlib.md5(raw_bytes).hexdigest()[:10]\n",
        "\n",
        "    # 최종 chunk_id 구성\n",
        "    # 형식: \"{페이지}_{청크인덱스}_{해시}\"\n",
        "    d.metadata[\"chunk_id\"] = f\"{page}_{i}_{h}\"\n",
        "\n",
        "    # 결과적으로 d.metadata에는 다음이 추가됨:\n",
        "    # {\"source\":, \"page\":, \"chunk_id\":}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DQGds50B4ICx"
      },
      "outputs": [],
      "source": [
        "# 청크 결과물 저장 경로\n",
        "chunks_path = cfg.raw_dir / \"chunks.pkl\"\n",
        "\n",
        "# 청크 불러오기\n",
        "with open(chunks_path, \"wb\") as f:\n",
        "    pickle.dump(docs, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "lhReZ58v4ICx"
      },
      "outputs": [],
      "source": [
        "# 저장한 청크 불러오기\n",
        "if Path.exists(chunks_path):\n",
        "    with open(chunks_path, \"rb\") as f:\n",
        "        docs = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "DF86JRP14ICx",
        "outputId": "e06246bf-ca67-4446-aa51-d7af174417f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'producer': 'ezPDF Builder Supreme', 'creator': 'PyPDF', 'creationdate': '2024-12-22T23:44:00+09:00', 'moddate': '2025-01-09T17:28:20+09:00', 'source': 'data/2024년_원천징수의무자를위한연말정산신간고안내.pdf', 'total_pages': 426, 'page': 1, 'page_label': '2', 'chunk_id': '1_1_32862a711b'}, page_content='머 리 말\\n어려운 경제 상황 속에서도 항상 성실하게 원천징수의무를 이행하여 국세행정에  \\n협력해주신 원천징수의무자(회사)와 성실하게 세금을 납부하신 근로자 여러분께 진심\\n으로 감사드립니다.\\n그동안 국세청은 「연말정산 미리보기」, 「편리한 연말정산」 시스템과 「간소화자료  \\n일괄제공」 서비스를 시행하는 등 디지털 납세서비스를 제공하고 「맞춤형안내」를 통해 \\n성실 납세를 지원해 왔습니다.\\n더불어, 2024년 귀속부터는 소득기준 초과 부양가족에 대한 자료 조회 및 다운로드를  \\n제한하여 납세자의 실수를 최소화하고 정확한 연말정산을 지원하기 위해 「간소화  \\n서비스」를 전면 개편합니다.\\n이 책자에는 세법 개정사항과 최신 예규, 소득·세액공제신고서 작성 방법, 홈택스를 \\n이용한 지급명세서 제출 방법 등을 분야별로 담아 납세자에게 실질적인 도움이 될 수 \\n있도록 구성하였습니다.\\n책자에 수록된 내용 외에도 연말정산 주요정보, 동영상 자료, 계산 사례, 체크리스트 등 \\n다양한 자료를 국세청 누리집(www.nts.go.kr) 연말정산 종합안내에서 제공하고 있습니다.\\n본 책자가 연말정산에 관한 납세자 여러분의 궁금증을 해소하고, 원천징수의무 이행에 \\n유용한 참고자료로 활용되어 성실신고·납부에 도움이 되기를 바랍니다.\\n2024년 12월\\n법인납세국장     \\n연말정산\\n신고안내\\n2024 원천징수의무자를 위한')"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 청크 샘플 확인\n",
        "docs[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQYk9wRf4ICy"
      },
      "source": [
        "# 4. Retriever 처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "SfvBWPB24ICy"
      },
      "outputs": [],
      "source": [
        "# FAISS 벡터 DB 생성\n",
        "# docs는 split된 Document 리스트\n",
        "vectorstore = FAISS.from_documents(\n",
        "    docs,\n",
        "    embeddings\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ew8hZ5Ts4ICy"
      },
      "outputs": [],
      "source": [
        "# Faiss 벡터 DB 저장 경로\n",
        "faiss_path = cfg.raw_dir / \"faiss\"\n",
        "\n",
        "# Faiss 벡터 저장\n",
        "vectorstore.save_local(faiss_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "UMKmvYlK4ICy"
      },
      "outputs": [],
      "source": [
        "# Faiss 불러오기\n",
        "if Path.exists(faiss_path):\n",
        "    vectorstore = FAISS.load_local(\n",
        "        faiss_path,\n",
        "        embeddings,\n",
        "        allow_dangerous_deserialization=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "9-vAgHKl4ICy"
      },
      "outputs": [],
      "source": [
        "# 임베딩 Retriever 생성\n",
        "dense_retriever = vectorstore.as_retriever(\n",
        "    search_kwargs={\"k\": cfg.dense_k}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cYBJbNCp4ICy"
      },
      "outputs": [],
      "source": [
        "# bm25 Retriever 생성\n",
        "bm25_retriever = BM25Retriever.from_documents(docs)\n",
        "\n",
        "# bm25 저장 경로\n",
        "bm25_path = cfg.raw_dir / \"bm25.pkl\"\n",
        "\n",
        "# 저장\n",
        "with bm25_path.open(\"wb\") as f:\n",
        "    pickle.dump(bm25_retriever, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "dINE1Dvm4ICy"
      },
      "outputs": [],
      "source": [
        "# 저장한 bm25 불러오기\n",
        "with bm25_path.open(\"rb\") as f:\n",
        "    bm25_retriever = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "GesR8fQ24ICy"
      },
      "outputs": [],
      "source": [
        "# bm25 Retriever 설정\n",
        "bm25_retriever.k = cfg.sparse_k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Th8nQaGU4ICy"
      },
      "outputs": [],
      "source": [
        "# RRF (Reciprocal Rank Fusion)\n",
        "def rrf_fuse(\n",
        "    dense_docs: List[Document],   # Dense(임베딩 기반) 검색 결과 (순서 있음)\n",
        "    sparse_docs: List[Document],  # Sparse(BM25 등 키워드 기반) 검색 결과 (순서 있음)\n",
        "    k: int,\n",
        ") -> List[Tuple[Document, float]]:\n",
        "    \"\"\"\n",
        "    RRF 공식:\n",
        "        score(d) = Σ 1 / (k + rank)\n",
        "\n",
        "    - 각 검색기의 순위를 점수로 변환하여 누적\n",
        "    - 여러 검색기에서 동시에 상위권인 문서를 우선시\n",
        "    - 반환: (Document, RRF 점수) 리스트\n",
        "    \"\"\"\n",
        "\n",
        "    # scores:\n",
        "    # - key   : 문서 고유 ID (chunk_id)\n",
        "    # - value : RRF 누적 점수\n",
        "    scores: Dict[str, float] = {}\n",
        "\n",
        "    # pool:\n",
        "    # - key   : 문서 고유 ID (chunk_id)\n",
        "    # - value : 실제 Document 객체\n",
        "    # - 정렬은 scores로 하고, 반환 시 Document를 꺼내기 위해 사용\n",
        "    pool: Dict[str, Document] = {}\n",
        "\n",
        "    # 하나의 검색 결과 리스트(dense 또는 sparse)를 RRF 점수로 변환하여 누적하는 내부 함수\n",
        "    def add(rank_list: List[Document]):\n",
        "        # enumerate(start=1):\n",
        "        # RRF에서 rank는 1부터 시작하는 것이 표준\n",
        "        for r, d in enumerate(rank_list, start=1):\n",
        "\n",
        "            # 문서를 유일하게 식별하기 위한 ID\n",
        "            # - chunk_id가 있으면 사용\n",
        "            # - 없을 경우, 임시로 텍스트 앞부분을 사용 (fallback)\n",
        "            doc_id = d.metadata.get(\"chunk_id\") or d.page_content[:80]\n",
        "\n",
        "            # 문서 ID에 해당하는 Document 객체를 저장\n",
        "            # - 나중에 정렬된 ID를 Document로 되돌리기 위함\n",
        "            pool[doc_id] = d\n",
        "\n",
        "            # RRF 점수 누적:\n",
        "            # - 이미 점수가 있으면 더하고\n",
        "            # - 없으면 0에서 시작\n",
        "            # - r이 작을수록(상위 순위일수록) 더 큰 점수 기여\n",
        "            scores[doc_id] = scores.get(doc_id, 0.0) + 1.0 / (k + r)\n",
        "\n",
        "    # Dense 검색 결과를 RRF 점수에 반영\n",
        "    add(dense_docs)\n",
        "\n",
        "    # Sparse 검색 결과를 RRF 점수에 반영\n",
        "    add(sparse_docs)\n",
        "\n",
        "    # 누적된 RRF 점수를 기준으로 문서 ID를 내림차순 정렬\n",
        "    # scores.items(): (doc_id, score) 형태\n",
        "    ranked = sorted(\n",
        "        scores.items(),\n",
        "        key=lambda x: x[1],  # score 기준 정렬\n",
        "        reverse=True         # 점수 높은 순\n",
        "    )\n",
        "\n",
        "    # 정렬된 doc_id를 실제 Document 객체로 변환하여 반환\n",
        "    # 반환 형태: [(Document, score), ...]\n",
        "    return [(pool[doc_id], score) for doc_id, score in ranked]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "v0CtKsP14ICy",
        "outputId": "113dcfa6-fa28-4ff5-cd3e-92cc1444bc51"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The CrossEncoder `cache_dir` argument was renamed and is now deprecated, please use `cache_folder` instead.\n"
          ]
        }
      ],
      "source": [
        "# Cross-Encoder Reranker 설정\n",
        "# RRF 이후 후보 문서들을 query-문서 쌍 단위로 평가\n",
        "\n",
        "# Cross-Encoder reranker 모델 ID\n",
        "RERANK_MODEL_ID = \"BAAI/bge-reranker-v2-m3\"\n",
        "\n",
        "# reranker 모델을 저장할 로컬 디렉터리\n",
        "rerank_dir = cfg.model_dir / \"rerank\"\n",
        "\n",
        "# CrossEncoder 인스턴스 생성\n",
        "reranker = CrossEncoder(\n",
        "    RERANK_MODEL_ID,\n",
        "    cache_dir=rerank_dir,\n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        ")\n",
        "\n",
        "# Cross-Encoder 기반 재정렬 함수\n",
        "def cross_encoder_rerank(\n",
        "    query: str,\n",
        "    candidates: List[Document],\n",
        "    top_n: int,\n",
        ") -> List[Tuple[Document, float]]:\n",
        "    \"\"\"\n",
        "    Cross-Encoder를 사용해 (query, document) 쌍마다 점수를 계산한 뒤\n",
        "    점수 기준으로 내림차순 정렬하여 반환한다.\n",
        "\n",
        "    반환 형태:\n",
        "        [(Document, score), ...]\n",
        "    \"\"\"\n",
        "    # 상위 top_n개만 사용\n",
        "    candidates = candidates[:top_n]\n",
        "\n",
        "    # Cross-Encoder 입력 형태 생성\n",
        "    # 각 문서에 대해 (query, document_text) 쌍\n",
        "    pairs = [(query, d.page_content) for d in candidates]\n",
        "\n",
        "    scores = reranker.predict(pairs)\n",
        "\n",
        "    # 문서와 점수를 묶어서 정렬\n",
        "    # zip으로 (Document, score) 형태로 묶음\n",
        "    reranked = sorted(\n",
        "        list(zip(candidates, [float(s) for s in scores])),\n",
        "        key=lambda x: x[1],   # score 기준\n",
        "        reverse=True\n",
        "    )\n",
        "\n",
        "    return reranked\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KFw6sP0H4ICy"
      },
      "outputs": [],
      "source": [
        "# 최종 context 생성 함수\n",
        "def build_context_from_docs(\n",
        "    ranked_docs: List[Tuple[Document, float]],\n",
        "    final_k: int,\n",
        "    max_context_chars: int,\n",
        ") -> str:\n",
        "    parts = []\n",
        "    total = 0\n",
        "\n",
        "    # 최종 k기준으로 처리(max_context_chars까지)\n",
        "    for doc, score in ranked_docs[:final_k]:\n",
        "        page = doc.metadata.get(\"page\", \"NA\")\n",
        "        cid = doc.metadata.get(\"chunk_id\", \"NA\")\n",
        "\n",
        "        block = f\"[p.{page} | {cid} | rerank={score:.3f}]\\n{doc.page_content}\"\n",
        "        if total + len(block) > max_context_chars:\n",
        "            break\n",
        "\n",
        "        parts.append(block)\n",
        "        total += len(block)\n",
        "\n",
        "    return \"\\n\\n\".join(parts).strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzzC4Gkv5UEy"
      },
      "source": [
        "# 5. Query 처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "HTpyFBUp4ICy"
      },
      "outputs": [],
      "source": [
        "# Query Rewriter\n",
        "rewrite_prompt = ChatPromptTemplate.from_template(\n",
        "\"\"\"\n",
        "너는 '국세청 연말정산 안내서(PDF)'에서 검색이 잘 되도록 질문을 재작성하는 Query Rewriter다.\n",
        "\n",
        "목표:\n",
        "- 문서에서 찾기 쉬운 \"검색용 질문 1개\"로 바꾼다.\n",
        "\n",
        "규칙:\n",
        "1. 원래 의미는 유지한다.\n",
        "2. 연말정산/원천징수/간소화/공제/세액공제/제출기한/홈택스 경로 같은 문서 용어를 우선 사용한다.\n",
        "3. 기간/연도(2024, 2025), 조건(소득요건, 한도)을 가능하면 포함한다.\n",
        "4. 출력은 반드시 한 줄 한국어. 불릿/설명/따옴표/추가 문장 금지.\n",
        "\n",
        "[원문 질문]\n",
        "{q}\n",
        "\n",
        "[출력: 검색용 질문 1줄]\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# Query rewriter 함수 작성\n",
        "def rewrite_query(q: str) -> str:\n",
        "    out = (rewrite_prompt | llm).invoke(\n",
        "        {\"q\": q},\n",
        "        config={\"callbacks\": [langfuse_handler]},\n",
        "    )\n",
        "    text = str(out).strip()\n",
        "\n",
        "    # 출력 라인만 뽑기\n",
        "    m = re.search(r\"(?:출력\\s*[:：]|검색용 질문\\s*[:：])\\s*(.*)\", text, flags=re.IGNORECASE)\n",
        "    if m:\n",
        "        text = m.group(1).strip()\n",
        "    else:\n",
        "        # fallback: 첫 줄\n",
        "        text = text.splitlines()[0].strip()\n",
        "\n",
        "    # 같은 줄에 뒤로 더 붙으면 첫 줄만 유지\n",
        "    text = text.splitlines()[0].strip()\n",
        "\n",
        "    # 라벨 제거\n",
        "    text = re.sub(r\"^(Human:|Assistant:)\\s*\", \"\", text, flags=re.IGNORECASE).strip()\n",
        "\n",
        "    # 따옴표/특수따옴표 제거, 공백 정리\n",
        "    text = text.replace('\"', \"\").replace(\"“\", \"\").replace(\"”\", \"\")\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "    # rewritten이 너무 짧거나 깨지면 원문 사용\n",
        "    if len(text) < 5:\n",
        "        return q.strip()\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbmGP8ZM5ixR"
      },
      "source": [
        "# 6. 1차 답변 처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "96Vhx5324ICy"
      },
      "outputs": [],
      "source": [
        "# 답변 프롬프트\n",
        "answer_prompt = ChatPromptTemplate.from_template(\n",
        "\"\"\"\n",
        "당신은 '국세청 연말정산 안내서(PDF)'의 **문구를 재진술하는 역할만** 수행한다.\n",
        "\n",
        "규칙 (매우 중요):\n",
        "1. [문서 근거]에 **명시적으로 존재하는 내용만** bullet로 옮긴다.\n",
        "2. 문서에 없는 개념, 요약, 일반화, 재해석, 사례 추가를 절대 하지 않는다.\n",
        "3. 질문에 정확히 대응되는 문장이 문서에 없으면\n",
        "   반드시 \"문서에 없는 정보입니다.\" 한 줄만 출력한다.\n",
        "4. 질문을 쪼개거나, 새로운 질문을 만들지 않는다.\n",
        "5. 답변은 bullet(-)로만 구성한다.\n",
        "\n",
        "[문서 근거]\n",
        "{context}\n",
        "\n",
        "[질문]\n",
        "{q}\n",
        "\n",
        "[답변]\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# pdf 기반 답변 함수 작성\n",
        "def answer_from_pdf_context(q: str, context: str) -> str:\n",
        "    out = (answer_prompt | llm).invoke(\n",
        "        {\"q\": q, \"context\": context},\n",
        "        config={\"callbacks\": [langfuse_handler]},\n",
        "    )\n",
        "    text = str(out)\n",
        "\n",
        "    # '[답변]' 이후만 가져오도록 고정\n",
        "    if \"[답변]\" in text:\n",
        "        text = text.split(\"[답변]\", 1)[1]\n",
        "\n",
        "    # Human/Assistant 라벨 제거\n",
        "    text = re.sub(r\"^\\s*(Human:|Assistant:)\\s*\", \"\", text, flags=re.IGNORECASE | re.MULTILINE).strip()\n",
        "\n",
        "    # 라인 단위 정리\n",
        "    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
        "\n",
        "    # 문서 명사 토큰\n",
        "    doc_tokens = set(re.findall(r\"[가-힣]{2,}\", context))\n",
        "\n",
        "    bullets = []\n",
        "    for ln in lines:\n",
        "        # bullet만 수집\n",
        "        if not ln.startswith((\"-\", \"•\", \"○\")):\n",
        "            continue\n",
        "\n",
        "        # 근거성 체크(너무 빡세면 답이 다 날아가니까 2개 교집합만 요구)\n",
        "        nouns = set(re.findall(r\"[가-힣]{2,}\", ln))\n",
        "        if doc_tokens and len(nouns & doc_tokens) < 2:\n",
        "            continue\n",
        "\n",
        "        bullets.append(ln)\n",
        "\n",
        "    if not bullets:\n",
        "        return \"문서에 없는 정보입니다.\"\n",
        "\n",
        "    # 중복 bullet 제거(동일 문장 반복 방지)\n",
        "    uniq = []\n",
        "    seen = set()\n",
        "    for b in bullets:\n",
        "        key = re.sub(r\"\\s+\", \" \", b)\n",
        "        if key not in seen:\n",
        "            uniq.append(b)\n",
        "            seen.add(key)\n",
        "\n",
        "    return \"\\n\".join(uniq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zxvcbm0H5onx"
      },
      "source": [
        "# 7. 웹검색 기반 2차 답변 처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "cAJhk5A64ICy"
      },
      "outputs": [],
      "source": [
        "# 문서를 우선 탐색하되, 웹 검색으로 넘어갈지 판단하는 게이트(gate) 함수 생성\n",
        "#\n",
        "# 목적:\n",
        "# - RAG의 1차 근거는 \"PDF 문서\"로 유지\n",
        "# - 문서 검색 결과가 부실/애매할 때만 웹검색(DuckDuckGo)으로 보조\n",
        "def need_web_fallback(\n",
        "    reranked: List[Tuple[Document, float]],\n",
        "    context: str,\n",
        "    min_score: float,\n",
        "    min_margin: float,\n",
        ") -> bool:\n",
        "    \"\"\"\n",
        "    웹검색 fallback 조건\n",
        "\n",
        "    1. reranked 없음 -> True\n",
        "    2. top1이 매우 낮음 -> True\n",
        "    3. top1이 낮은 편인데(top1 < strong_enough) top1-top2도 작으면 애매 -> True\n",
        "    4. context가 거의 비었으면 -> True\n",
        "    \"\"\"\n",
        "    if not reranked:\n",
        "        return True\n",
        "\n",
        "    top1 = float(reranked[0][1])\n",
        "\n",
        "    # 컨텍스트가 사실상 비었으면 웹 고려\n",
        "    if not context or len(context.strip()) < 200:\n",
        "        return True\n",
        "\n",
        "    # top1이 일정 점수보다 높으면 문서 근거 충분으로 보고 margin 체크 자체를 생략\n",
        "    strong_enough = min_score + 0.10  # (기본 min_score=0.15라면 strong_enough=0.25)\n",
        "\n",
        "    if top1 < min_score:\n",
        "        return True\n",
        "\n",
        "    # top1이 충분히 높으면 애매해도 웹으로 안 감\n",
        "    if top1 >= strong_enough:\n",
        "        return False\n",
        "\n",
        "    # 여기부터는 top1이 높진 않은 구간 -> margin으로 애매함 판단\n",
        "    if len(reranked) >= 2:\n",
        "        top2 = float(reranked[1][1])\n",
        "        if (top1 - top2) < min_margin:\n",
        "            return True\n",
        "\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Rixjgkl-4ICy"
      },
      "outputs": [],
      "source": [
        "# duckduckgo 검색 엔진 생성\n",
        "ddg = DuckDuckGoSearchRun()\n",
        "\n",
        "web_answer_prompt = ChatPromptTemplate.from_template(\n",
        "\"\"\"\n",
        "너는 검색 결과를 **사실 그대로 요약만 하는 도구**다.\n",
        "\n",
        "절대 금지:\n",
        "- 검증, 평가, 수정, 요청, 재질문\n",
        "- 가정, 추론, 보완 설명\n",
        "- 메타 발언 (\"검증 결과\", \"수정 요청\" 등)\n",
        "\n",
        "규칙:\n",
        "1. 검색 결과에 실제로 포함된 문장만 사용한다.\n",
        "2. 각 항목은 불릿(-) 하나의 문장으로 작성한다.\n",
        "3. 최대 3개 항목까지만 출력한다.\n",
        "4. 불릿 외의 텍스트는 절대 출력하지 않는다.\n",
        "\n",
        "[질문]\n",
        "{q}\n",
        "\n",
        "[검색 결과]\n",
        "{search_results}\n",
        "\n",
        "[출력]\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# 웹기반 답변 생성 함수\n",
        "def web_fallback_answer(q: str) -> str:\n",
        "    # DDG 검색\n",
        "    search_results = ddg.run(q)\n",
        "\n",
        "    # 프롬프트 주입\n",
        "    out = (web_answer_prompt | llm).invoke(\n",
        "        {\"q\": q, \"search_results\": search_results},\n",
        "        config={\"callbacks\": [langfuse_handler]},\n",
        "    )\n",
        "    text = str(out).strip()\n",
        "\n",
        "    # 후처리: '-' 불릿만 남기고 최대 3줄로 컷 (모델이 딴소리하면 강제로 잘라냄)\n",
        "    lines = []\n",
        "    for ln in text.splitlines():\n",
        "        ln = ln.strip()\n",
        "        if ln.startswith(\"- \"):\n",
        "            lines.append(ln)\n",
        "        if len(lines) >= 3:\n",
        "            break\n",
        "\n",
        "    # 불릿이 없으면 최소한 형태 강제\n",
        "    if not lines:\n",
        "        return \"- (추가 참고) 검색 결과 요약을 생성하지 못했습니다. ※ 국세청/홈택스 공식 공지 확인 권장\"\n",
        "\n",
        "    return \"\\n\".join(lines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agpgguMa4ICy"
      },
      "source": [
        "# 8. 랭그래프 에이전트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "xbyTMUqV4ICy"
      },
      "outputs": [],
      "source": [
        "# 상태 정의\n",
        "class RAGState(TypedDict):\n",
        "    question: str   # query\n",
        "    rewritten: str  # rewrite 처리된 query\n",
        "\n",
        "    # retrieval 파트\n",
        "    rrf_ranked: List[Tuple[Document, float]] # rrf 처리된 결과물\n",
        "    reranked: List[Tuple[Document, float]]   # Cross-Encoder로 rerank된 결과물\n",
        "    context: str\n",
        "\n",
        "    # outputs\n",
        "    answer: str     # 기본 답변\n",
        "    need_web: bool  # 웹 검색 게이트\n",
        "    web_answer: str # 웬기반 답변"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "BrUZOPeD4ICz"
      },
      "outputs": [],
      "source": [
        "# rewrite 노드\n",
        "def node_rewrite(state: RAGState) -> RAGState:\n",
        "    q = state[\"question\"]\n",
        "    rq = rewrite_query(q)\n",
        "    # 각 노드는 상태를 수정하는 것이 아닌 새로운 상태를 반환\n",
        "    return {**state, \"rewritten\": rq}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Gs8z2eYX4IC1"
      },
      "outputs": [],
      "source": [
        "# pre-retrieve 노드\n",
        "def node_retrieve_rrf(state: RAGState) -> RAGState:\n",
        "    q = state[\"rewritten\"]\n",
        "\n",
        "    dense_docs = dense_retriever.invoke(q)\n",
        "    sparse_docs = bm25_retriever.invoke(q)\n",
        "\n",
        "    rrf_ranked = rrf_fuse(dense_docs, sparse_docs, k=cfg.rrf_k)\n",
        "    rrf_ranked = rrf_ranked[:cfg.rrf_pool]\n",
        "\n",
        "    return {**state, \"rrf_ranked\": rrf_ranked}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "kTDgRuz_4IC1"
      },
      "outputs": [],
      "source": [
        "# post-retrieve 노드\n",
        "def node_rerank(state: RAGState) -> RAGState:\n",
        "    q = state[\"rewritten\"]\n",
        "\n",
        "    # RRF 결과에서 doc만 뽑아 reranker 후보로 사용\n",
        "    candidates = [d for d, _ in state[\"rrf_ranked\"]]\n",
        "    reranked = cross_encoder_rerank(q, candidates, top_n=cfg.rerank_top_n)\n",
        "\n",
        "    return {**state, \"reranked\": reranked}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "yJ6Lnmte4IC1"
      },
      "outputs": [],
      "source": [
        "# 웹검색 게이트\n",
        "def node_gate(state: RAGState) -> RAGState:\n",
        "    reranked = state[\"reranked\"]\n",
        "\n",
        "    context = build_context_from_docs(\n",
        "        ranked_docs=reranked,\n",
        "        final_k=cfg.final_k,\n",
        "        max_context_chars=cfg.max_context_chars,\n",
        "    )\n",
        "\n",
        "    need_web = need_web_fallback(\n",
        "        reranked=reranked,\n",
        "        context=context,\n",
        "        min_score=cfg.rerank_min_score,\n",
        "        min_margin=cfg.rerank_min_margin,\n",
        "    )\n",
        "\n",
        "    return {**state, \"context\": context, \"need_web\": need_web}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_HGDuRS4IC1"
      },
      "outputs": [],
      "source": [
        "# Answer 노드\n",
        "def node_answer(state: RAGState) -> RAGState:\n",
        "    q = state[\"question\"]\n",
        "    context = state[\"context\"]\n",
        "\n",
        "    ans = answer_from_pdf_context(q, context)\n",
        "\n",
        "    # 답변 자체가 \"문서에 없는 정보\"면 web fallback 강제\n",
        "    if ans.strip() == \"문서에 없는 정보입니다.\":\n",
        "        return {\n",
        "            **state,\n",
        "            \"answer\": ans,\n",
        "            \"need_web\": True,\n",
        "        }\n",
        "\n",
        "    return {**state, \"answer\": ans}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Zbh1fOmC4IC1"
      },
      "outputs": [],
      "source": [
        "# 웹 노드\n",
        "def node_web(state: RAGState) -> RAGState:\n",
        "    q = state[\"question\"]\n",
        "    wab = web_fallback_answer(q)\n",
        "    return {**state, \"web_answer\": wab}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "83ZKqsFQ4IC1"
      },
      "outputs": [],
      "source": [
        "# pdf 기반 답변 + 웹 답변 병합 노드\n",
        "def node_merge(state: RAGState) -> RAGState:\n",
        "    \"\"\"\n",
        "    문서 답변 + (추가 참고) 웹 검색을 분리해서 붙인다.\n",
        "    \"\"\"\n",
        "    if state.get(\"need_web\", False):\n",
        "        merged = state[\"answer\"].strip() + \"\\n\\n(추가 참고: DuckDuckGo 웹 검색)\\n\" + state.get(\"web_answer\", \"\").strip()\n",
        "        return {**state, \"answer\": merged}\n",
        "    return state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "TXSlGNYw4IC1"
      },
      "outputs": [],
      "source": [
        "# 조건 분기 함수 정의\n",
        "# answer 노드 실행 후, state를 보고 다음 노드를 결정\n",
        "def route_after_answer(state: RAGState):\n",
        "    # state[\"need_web\"]가 True이면 웹검색 노드로 이동\n",
        "    # False이거나 없으면 바로 merge 단계로 이동\n",
        "    return \"web\" if state.get(\"need_web\", False) else \"merge\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "qChE5_4m4IC1"
      },
      "outputs": [],
      "source": [
        "# LangGraph 구성: RAG 전체 파이프라인 정의\n",
        "\n",
        "# StateGraph 생성\n",
        "g = StateGraph(RAGState)\n",
        "\n",
        "# 노드 등록\n",
        "\n",
        "# 1. 사용자 질문을 검색 친화적으로 재작성\n",
        "g.add_node(\"rewrite\", node_rewrite)\n",
        "\n",
        "# 2. Dense + Sparse 검색 후 RRF로 통합 retrieval\n",
        "g.add_node(\"retrieve_rrf\", node_retrieve_rrf)\n",
        "\n",
        "# 3. Cross-Encoder 기반 재정렬\n",
        "g.add_node(\"rerank\", node_rerank)\n",
        "\n",
        "# 4. 웹 노드 게이트\n",
        "g.add_node(\"gate\", node_gate)\n",
        "\n",
        "# 4. 문서 기반 답변 생성 (1차 답변 시도)\n",
        "g.add_node(\"answer\", node_answer)\n",
        "\n",
        "# 5. 외부 웹검색 노드\n",
        "g.add_node(\"web\", node_web)\n",
        "\n",
        "# 6. 문서 답변 + 웹 답변 최종 병합\n",
        "g.add_node(\"merge\", node_merge)\n",
        "\n",
        "# Entry point 설정\n",
        "g.set_entry_point(\"rewrite\")\n",
        "\n",
        "# 기본적인 직선형(edge) 흐름 정의\n",
        "g.add_edge(\"rewrite\", \"retrieve_rrf\")\n",
        "g.add_edge(\"retrieve_rrf\", \"rerank\")\n",
        "g.add_edge(\"rerank\", \"gate\")\n",
        "g.add_edge(\"gate\", \"answer\")\n",
        "\n",
        "# 조건부 edge 등록\n",
        "# answer 노드 이후에만 조건 분기 발생\n",
        "g.add_conditional_edges(\n",
        "    \"answer\",\n",
        "    route_after_answer,\n",
        "    {\n",
        "        \"web\": \"web\",         # \"web\" 반환 시 web 노드\n",
        "        \"merge\": \"merge\",     # \"merge\" 반환 시 merge 노드\n",
        "    }\n",
        ")\n",
        "\n",
        "# web 노드를 거쳤을 경우의 흐름\n",
        "# - 웹검색 결과를 얻은 뒤, merge 단계로 합류\n",
        "g.add_edge(\"web\", \"merge\")\n",
        "\n",
        "# merge 이후 그래프 종료\n",
        "g.add_edge(\"merge\", END)\n",
        "\n",
        "# 그래프 컴파일\n",
        "app = g.compile()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "aGJQXl344IC1",
        "outputId": "69476bf9-71b7-4ffa-c943-a92f7c387492"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Q: 연말정산 때 비거주자는 세액공제신고서를 어떻게 작성해야 해?\n",
            "\n",
            "A:\n",
            " • 비거주자의 국내원천소득에 대해서는 「소득세법」 제122조에 따라 거주자의 계산규정을 준용합니다.\n",
            "• 「소득세법」 제51조 제3항에 따른 인적공제 중 비거주자 본인 외의 자에 대한 공제는 적용되지 않습니다.\n",
            "• 「소득세법」 제59조의2에 따른 자녀세액공제 역시 적용되지 않습니다.\n",
            "• 「소득세법」 제59조의4에 따른 특별세액공제 역시 적용되지 않습니다.\n",
            "• 「소득세법」 제59조에 따른 근로소득세액공제만 적용됩니다.\n",
            "• 「소득세법」 제59조에서 규정하는 근로소득세액공제만을 적용합니다.\n",
            "rewritten: 비거주자의 연말정산 세액공제신고서 작성 방법\n",
            "top1 rerank: 0.9649685025215149\n",
            "need_web: False\n",
            "\n",
            "================================================================================\n",
            "Q: 2024년 개정 세법 중에 월세와 관련한 내용이 있을까?\n",
            "\n",
            "A:\n",
            " • 총급여액 8천만원 이하인 근로자 및 성실사업자 (p.215)\n",
            "• 국민주택규모(85㎡ 이하) 또는 기준시가 4억원 이하 주택 임차자 (p.215)\n",
            "• 월세액 연간 1,000만원 한도 (p.216)\n",
            "rewritten: 월세 관련 소득 공제 혜택 변경 사항 확인 (2024년 기준)\n",
            "top1 rerank: 0.9686283469200134\n",
            "need_web: False\n",
            "\n",
            "================================================================================\n",
            "Q: 외국인 근로자의 경우에는 어떤 점에 주의해야 할까?\n",
            "\n",
            "A:\n",
            " - ’24년 귀속 급여 중 미지급 급여는 해당 과세기간의 12월 31일에 지급한 것으로 보임\n",
            "- 일용근로자는 건설공사 종사자 제외 3개월 이상 연속 근무 시 일반급여자로 처리\n",
            "- 인정상여는 주택자금 대여 이자, 퇴직금 인정 이자, 회사 제품 무상 지급 현물 급여 등 포함\n",
            "- 단, 할인판매가격이 법인 취득가액 이상이고 일반 소비자 판매가 대비 현저히 낮지 않은 경우 제외\n",
            "- 국내원천소득에는 근로소득, 거주자 외국인 임원의 급여, 내국법인 임원의 급여, 법인세 상여금 포함\n",
            "- 연말정산 시 거주자와 동일한 계산규정을 적용하되, 비거주자 본인 외 인적공제, 특별소득공제, 자녀세액공제, 특별세액공제 제외\n",
            "- 예시: 기부금 영수증 일련번호 확인 필수, 고유번호증 유무는 적격 단체 판단의 기준 아님\n",
            "- 월세액 세액공제 신청 시 주민등록표 등본상 세대주 여부 확인 필요\n",
            "- 대한민국 국적을 가진 재외국민은 해당되지 않음\n",
            "- 외국인 단일세율(19%) 적용\n",
            "- 외국인 기술자 세액감면 적용\n",
            "- 조특법 §18의2에 따른 지역본부 근무자 한정 적용\n",
            "- 과세연도 종료일 현재 대한민국 국적 보유자 제외\n",
            "rewritten: 외국인 근로자 연말정산 시 유의사항 및 확인 사항\n",
            "top1 rerank: 0.9198170304298401\n",
            "need_web: False\n",
            "\n",
            "================================================================================\n",
            "Q: 연말정산 간소화자료 일괄제공 서비스의 동의 기간이 언제야?\n",
            "\n",
            "A:\n",
            " 문서에 없는 정보입니다.\n",
            "\n",
            "(추가 참고: DuckDuckGo 웹 검색)\n",
            "- 2025년 12월 1일부터 2026년 1월 15일까지\n",
            "- 2025년 12월 1일부터 2026년 1월 15일까지\n",
            "- 2025년 12월 1일부터 2026년 1월 15일까지\n",
            "rewritten: **국세청 연말정산 간소화 자료 일괄제공 서비스 동의 기간**\n",
            "top1 rerank: 0.9817933440208435\n",
            "need_web: True\n",
            "\n",
            "================================================================================\n",
            "Q: 해외주식 양도소득도 공제 대상이야?\n",
            "\n",
            "A:\n",
            " 문서에 없는 정보입니다.\n",
            "\n",
            "(추가 참고: DuckDuckGo 웹 검색)\n",
            "- 해외 주식 양도 소득은 양도 소득세로 분류됩니다.\n",
            "- 해외 주식 양도 소득은 연말정산 시 인적 공제 소득 기준에 포함됩니다.\n",
            "- 해외 주식 양도 소득에 대한 양도 소득세는 22%의 세율을 적용합니다.\n",
            "rewritten: 국세청 연말정산 해외주식양도소득 공제 관련 문의\n",
            "top1 rerank: 0.5075260400772095\n",
            "need_web: True\n",
            "\n",
            "================================================================================\n",
            "Q: 프리랜서는 세액공제신고서 작성을 어떻게 해야 해?\n",
            "\n",
            "A:\n",
            " 문서에 없는 정보입니다.\n",
            "\n",
            "(추가 참고: DuckDuckGo 웹 검색)\n",
            "- 프리랜서는 홈택스에 접속하여 종합소득세 신고 메뉴를 선택한다.\n",
            "- 프리랜서의 소득공제 항목으로는 기본공제, 국민연금보험료 공제 등이 있다.\n",
            "- 프리랜서는 업무 관련 지출 증빙 서류(카드 내역, 영수증 등)를 준비해 신고서에 첨부한다.\n",
            "rewritten: 프리랜서 소득자 대상 2024년 세액공제신고서 작성 방법 및 제출 기한 확인\n",
            "top1 rerank: 0.8720290064811707\n",
            "need_web: True\n"
          ]
        }
      ],
      "source": [
        "# 실행 예시\n",
        "tests = [\n",
        "    \"연말정산 때 비거주자는 세액공제신고서를 어떻게 작성해야 해?\",\n",
        "    \"2024년 개정 세법 중에 월세와 관련한 내용이 있을까?\",\n",
        "    \"외국인 근로자의 경우에는 어떤 점에 주의해야 할까?\",\n",
        "    \"연말정산 간소화자료 일괄제공 서비스의 동의 기간이 언제야?\", # 문서에 없음: web fallback 확인용\n",
        "    \"해외주식 양도소득도 공제 대상이야?\",                     # 문서에 없음: web fallback 확인용\n",
        "    \"프리랜서는 세액공제신고서 작성을 어떻게 해야 해?\"          # 문서에 없음: web fallback 확인용\n",
        "]\n",
        "\n",
        "for q in tests:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"Q:\", q)\n",
        "    out = app.invoke({\"question\": q})\n",
        "    print(\"\\nA:\\n\", out[\"answer\"])\n",
        "    # 디버깅용\n",
        "    print(\"rewritten:\", out[\"rewritten\"])\n",
        "    if out.get(\"reranked\"):\n",
        "        print(\"top1 rerank:\", out[\"reranked\"][0][1])\n",
        "    print(\"need_web:\", out.get(\"need_web\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhovasQn4IC2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv (3.12.3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
